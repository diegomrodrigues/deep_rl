{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM2LjW25WwkXb7EzRu4GswY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bfc9a032faf64726b89990f900dcbbb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e68ce10d916444d88da160c76689f499",
              "IPY_MODEL_b2c654665726469499e8ac1d0f5a45a2",
              "IPY_MODEL_0c6c83f8d8a24400a3bbd7e15bb9cc8d",
              "IPY_MODEL_4f2a20c411a5451cae557fadd07f15b4"
            ],
            "layout": "IPY_MODEL_91ff96dd83db4b9a9761c05f7f687119"
          }
        },
        "ec3f305bd4704836aec041b2818465b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_852dbdbac469475dbfcb5c811afe58fb",
            "placeholder": "​",
            "style": "IPY_MODEL_87b44004a34e4d35b04f5925a00c023e",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "e3d221e3e6ad4a8ba095e0aaf0f7d568": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_c6fa47727bc74119a8038c7f2dccadf7",
            "placeholder": "​",
            "style": "IPY_MODEL_046b1a741b8845119376958f3c0f2e4d",
            "value": ""
          }
        },
        "974326c199c944cc8fac36484aabe29d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_e181831d580c46579b71ffd145a7ea2a",
            "style": "IPY_MODEL_a7e6d75d7e5940e68d7f3f6835e3c046",
            "value": true
          }
        },
        "4097a5c472f84c5f8d452d0a234d0363": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_10b226fe5c814488820c0ecc5af183b6",
            "style": "IPY_MODEL_b579406552694f428db1d228cffcb997",
            "tooltip": ""
          }
        },
        "c9ebb4f5a00d498ab4e751e54586f6a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c90af5b09ed0458a978fe7a46b3dfc01",
            "placeholder": "​",
            "style": "IPY_MODEL_e36be7c5c5414a02b0a6ed9c4a643177",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "91ff96dd83db4b9a9761c05f7f687119": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "852dbdbac469475dbfcb5c811afe58fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87b44004a34e4d35b04f5925a00c023e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c6fa47727bc74119a8038c7f2dccadf7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "046b1a741b8845119376958f3c0f2e4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e181831d580c46579b71ffd145a7ea2a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7e6d75d7e5940e68d7f3f6835e3c046": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "10b226fe5c814488820c0ecc5af183b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b579406552694f428db1d228cffcb997": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "c90af5b09ed0458a978fe7a46b3dfc01": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e36be7c5c5414a02b0a6ed9c4a643177": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b799f7349739495496be614e51e1e235": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_518581bc32be476183e78442e2aa7910",
            "placeholder": "​",
            "style": "IPY_MODEL_8d0c3f07039d48779cfb110ebf334618",
            "value": "Connecting..."
          }
        },
        "518581bc32be476183e78442e2aa7910": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d0c3f07039d48779cfb110ebf334618": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e68ce10d916444d88da160c76689f499": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f2234d3c5dc4f2f920f7afba6ad0f33",
            "placeholder": "​",
            "style": "IPY_MODEL_c50fc6d108ce49d18ef5e10453b5aca4",
            "value": "Token is valid (permission: write)."
          }
        },
        "b2c654665726469499e8ac1d0f5a45a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04e426a2c774402ebae560cd4dc1b34b",
            "placeholder": "​",
            "style": "IPY_MODEL_b914f6a23c704933b0d997ec4b1eec3c",
            "value": "Your token has been saved in your configured git credential helpers (store)."
          }
        },
        "0c6c83f8d8a24400a3bbd7e15bb9cc8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b1e1ae0d03e4d489f9e67ad88a7b032",
            "placeholder": "​",
            "style": "IPY_MODEL_5df51e7bf34b413f94c156672135e9d1",
            "value": "Your token has been saved to /root/.cache/huggingface/token"
          }
        },
        "4f2a20c411a5451cae557fadd07f15b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58e7cd9aee1c4241a514ff80eff7045c",
            "placeholder": "​",
            "style": "IPY_MODEL_96237893601248de90808df5990972bf",
            "value": "Login successful"
          }
        },
        "3f2234d3c5dc4f2f920f7afba6ad0f33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c50fc6d108ce49d18ef5e10453b5aca4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "04e426a2c774402ebae560cd4dc1b34b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b914f6a23c704933b0d997ec4b1eec3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3b1e1ae0d03e4d489f9e67ad88a7b032": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5df51e7bf34b413f94c156672135e9d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "58e7cd9aee1c4241a514ff80eff7045c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96237893601248de90808df5990972bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/diegomrodrigues/deep_rl/blob/main/DQN_CartPole_Agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade tensorboardX"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSCHuwoGdKNg",
        "outputId": "1afd3186-c1ee-4b16-9452-9f3eca712c59"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (1.25.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (24.0)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (3.20.3)\n",
            "Installing collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.6.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "bfc9a032faf64726b89990f900dcbbb3",
            "ec3f305bd4704836aec041b2818465b7",
            "e3d221e3e6ad4a8ba095e0aaf0f7d568",
            "974326c199c944cc8fac36484aabe29d",
            "4097a5c472f84c5f8d452d0a234d0363",
            "c9ebb4f5a00d498ab4e751e54586f6a7",
            "91ff96dd83db4b9a9761c05f7f687119",
            "852dbdbac469475dbfcb5c811afe58fb",
            "87b44004a34e4d35b04f5925a00c023e",
            "c6fa47727bc74119a8038c7f2dccadf7",
            "046b1a741b8845119376958f3c0f2e4d",
            "e181831d580c46579b71ffd145a7ea2a",
            "a7e6d75d7e5940e68d7f3f6835e3c046",
            "10b226fe5c814488820c0ecc5af183b6",
            "b579406552694f428db1d228cffcb997",
            "c90af5b09ed0458a978fe7a46b3dfc01",
            "e36be7c5c5414a02b0a6ed9c4a643177",
            "b799f7349739495496be614e51e1e235",
            "518581bc32be476183e78442e2aa7910",
            "8d0c3f07039d48779cfb110ebf334618",
            "e68ce10d916444d88da160c76689f499",
            "b2c654665726469499e8ac1d0f5a45a2",
            "0c6c83f8d8a24400a3bbd7e15bb9cc8d",
            "4f2a20c411a5451cae557fadd07f15b4",
            "3f2234d3c5dc4f2f920f7afba6ad0f33",
            "c50fc6d108ce49d18ef5e10453b5aca4",
            "04e426a2c774402ebae560cd4dc1b34b",
            "b914f6a23c704933b0d997ec4b1eec3c",
            "3b1e1ae0d03e4d489f9e67ad88a7b032",
            "5df51e7bf34b413f94c156672135e9d1",
            "58e7cd9aee1c4241a514ff80eff7045c",
            "96237893601248de90808df5990972bf"
          ]
        },
        "id": "oOEovtjgdHq9",
        "outputId": "e6ce35fc-12ca-4209-8cd1-3dddee276904"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bfc9a032faf64726b89990f900dcbbb3"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import gymnasium as gym\n",
        "from gymnasium.vector import SyncVectorEnv\n",
        "from dataclasses import dataclass\n",
        "from datetime import datetime\n",
        "from huggingface_hub import HFSummaryWriter\n",
        "\n",
        "NUM_FEATURES = 4\n",
        "NUM_ENVS = 100\n",
        "\n",
        "@dataclass\n",
        "class TrainConfig:\n",
        "    epochs: int\n",
        "    gamma: float\n",
        "    learning_rate: float\n",
        "\n",
        "@dataclass\n",
        "class Experiences:\n",
        "    states: list\n",
        "    actions: list\n",
        "    rewards: list\n",
        "    next_states: list\n",
        "    dones: list\n",
        "    total_reward: float\n",
        "\n",
        "def create_env():\n",
        "    def _make_env():\n",
        "        env = gym.make('CartPole-v1')\n",
        "        return env\n",
        "\n",
        "    return _make_env\n",
        "\n",
        "def create_envs(num_envs):\n",
        "    envs = [create_env() for _ in range(num_envs)]\n",
        "    return SyncVectorEnv(envs)\n",
        "\n",
        "def create_model(num_features, num_actions):\n",
        "    model = keras.Sequential([\n",
        "        layers.Input(shape=(num_features,)),\n",
        "        layers.Dense(512, activation='relu'),\n",
        "        layers.Dense(num_actions, activation='linear'),\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "def agent(model, state):\n",
        "    q_values = model(state)\n",
        "    return tf.argmax(q_values, axis=1)\n",
        "\n",
        "def collect_experiences(model, env, num_envs):\n",
        "    states, actions, rewards, next_states, dones = [], [], [], [], []\n",
        "    total_reward = 0\n",
        "\n",
        "    observations, _ = env.reset()\n",
        "    done = np.array([False] * num_envs)\n",
        "\n",
        "    while not all(done):\n",
        "        state = tf.convert_to_tensor(observations, dtype=tf.float32)\n",
        "        states.append(state)\n",
        "\n",
        "        action = agent(model, state)\n",
        "        observations, reward, termination, truncation, info = env.step(action.numpy())\n",
        "\n",
        "        actions.append(action)\n",
        "        rewards.append(tf.cast(reward, tf.float32))\n",
        "        next_states.append(tf.convert_to_tensor(observations, dtype=tf.float32))\n",
        "        dones.append(termination | truncation)\n",
        "\n",
        "        total_reward += np.sum(reward)\n",
        "        done = done | termination | truncation\n",
        "\n",
        "    return Experiences(states, actions, rewards, next_states, dones, total_reward)\n",
        "\n",
        "def prepare_experiences(experiences):\n",
        "    states = tf.concat(experiences.states, axis=0)\n",
        "    actions = tf.concat(experiences.actions, axis=0)\n",
        "    rewards = tf.concat(experiences.rewards, axis=0)\n",
        "    next_states = tf.concat(experiences.next_states, axis=0)\n",
        "    dones = tf.concat(experiences.dones, axis=0)\n",
        "\n",
        "    dones = tf.cast(dones, dtype=tf.float32)\n",
        "\n",
        "    return states, actions, rewards, next_states, dones\n",
        "\n",
        "def compute_targets(model, next_states, rewards, dones, gamma):\n",
        "    next_q_values = model(next_states)\n",
        "    next_q_max = tf.reduce_max(next_q_values, axis=1)\n",
        "    target_q_values = rewards + gamma * (1 - dones) * next_q_max\n",
        "    return target_q_values\n",
        "\n",
        "def mean_squared_error_loss(q_action, target_q_values):\n",
        "    return tf.reduce_mean(tf.square(target_q_values - q_action))\n",
        "\n",
        "def compute_loss(model, states, actions, target_q_values, num_actions):\n",
        "    q_values = model(states)\n",
        "    action_mask = tf.one_hot(actions, depth=num_actions)\n",
        "    q_action = tf.reduce_sum(q_values * action_mask, axis=-1)\n",
        "    loss = mean_squared_error_loss(q_action, target_q_values)\n",
        "    return loss\n",
        "\n",
        "def train_step(model, optimizer, experiences, gamma, num_actions, writer, step):\n",
        "    states, actions, rewards, next_states, dones = prepare_experiences(experiences)\n",
        "    target_q_values = compute_targets(model, next_states, rewards, dones, gamma)\n",
        "    with tf.GradientTape() as tape:\n",
        "        loss = compute_loss(model, states, actions, target_q_values, num_actions)\n",
        "\n",
        "    grads = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "    # Log metrics to TensorBoard\n",
        "    writer.add_scalar('loss', loss.numpy(), step)\n",
        "    writer.add_scalar('total_reward', experiences.total_reward, step)\n",
        "\n",
        "    return loss\n",
        "\n",
        "def train(model, env, config):\n",
        "    num_actions = env.single_action_space.n\n",
        "    optimizer = keras.optimizers.Adam(learning_rate=config.learning_rate)\n",
        "\n",
        "    repo_id = \"diegomrodrigues/CartPole-DQN\"\n",
        "    writer = HFSummaryWriter(repo_id=repo_id, commit_every=1)\n",
        "\n",
        "    for epoch in range(config.epochs):\n",
        "        experiences = collect_experiences(model, env, NUM_ENVS)\n",
        "        loss = train_step(model, optimizer, experiences, config.gamma, num_actions, writer, epoch)\n",
        "        print(f\"Epoch: {epoch+1}, Loss: {loss.numpy()}, Total Reward: {experiences.total_reward}\")\n",
        "\n",
        "    # Close the writer\n",
        "    writer.close()\n",
        "\n",
        "# main code\n",
        "\n",
        "env = create_envs(NUM_ENVS)\n",
        "model = create_model(NUM_FEATURES, env.single_action_space.n)\n",
        "\n",
        "train_config = TrainConfig(\n",
        "    epochs=1000,\n",
        "    gamma=0.99,\n",
        "    learning_rate=0.001\n",
        ")\n",
        "\n",
        "train(model, env, train_config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IoLMmI-zU3Y_",
        "outputId": "cb2748b5-daa2-41f6-b189-083a3445aaa4"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_experimental.py:57: UserWarning: 'HFSummaryWriter' is experimental and might be subject to breaking changes in the future. You can disable this warning by setting `HF_HUB_DISABLE_EXPERIMENTAL_WARNING=1` as environment variable.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, Loss: 1.0010871887207031, Total Reward: 1900.0\n",
            "Epoch: 2, Loss: 1.0016552209854126, Total Reward: 1000.0\n",
            "Epoch: 3, Loss: 1.0060248374938965, Total Reward: 1000.0\n",
            "Epoch: 4, Loss: 1.020082950592041, Total Reward: 1100.0\n",
            "Epoch: 5, Loss: 1.0325711965560913, Total Reward: 1100.0\n",
            "Epoch: 6, Loss: 1.0374184846878052, Total Reward: 1000.0\n",
            "Epoch: 7, Loss: 1.0629668235778809, Total Reward: 1100.0\n",
            "Epoch: 8, Loss: 1.0822651386260986, Total Reward: 1100.0\n",
            "Epoch: 9, Loss: 1.0930697917938232, Total Reward: 1000.0\n",
            "Epoch: 10, Loss: 1.115274429321289, Total Reward: 1000.0\n",
            "Epoch: 11, Loss: 1.1528236865997314, Total Reward: 1100.0\n",
            "Epoch: 12, Loss: 1.1797800064086914, Total Reward: 1100.0\n",
            "Epoch: 13, Loss: 1.2096812725067139, Total Reward: 1100.0\n",
            "Epoch: 14, Loss: 1.2425553798675537, Total Reward: 1100.0\n",
            "Epoch: 15, Loss: 1.276976466178894, Total Reward: 1100.0\n",
            "Epoch: 16, Loss: 1.3135631084442139, Total Reward: 1100.0\n",
            "Epoch: 17, Loss: 1.3542265892028809, Total Reward: 1100.0\n",
            "Epoch: 18, Loss: 1.3950917720794678, Total Reward: 1100.0\n",
            "Epoch: 19, Loss: 1.4463623762130737, Total Reward: 1100.0\n",
            "Epoch: 20, Loss: 1.4966270923614502, Total Reward: 1100.0\n",
            "Epoch: 21, Loss: 1.5398908853530884, Total Reward: 1100.0\n",
            "Epoch: 22, Loss: 1.6009838581085205, Total Reward: 1100.0\n",
            "Epoch: 23, Loss: 1.6711751222610474, Total Reward: 1100.0\n",
            "Epoch: 24, Loss: 1.7328612804412842, Total Reward: 1100.0\n",
            "Epoch: 25, Loss: 1.8054932355880737, Total Reward: 1100.0\n",
            "Epoch: 26, Loss: 1.8650697469711304, Total Reward: 1100.0\n",
            "Epoch: 27, Loss: 1.9165387153625488, Total Reward: 1100.0\n",
            "Epoch: 28, Loss: 2.0176937580108643, Total Reward: 1100.0\n",
            "Epoch: 29, Loss: 2.112506151199341, Total Reward: 1100.0\n",
            "Epoch: 30, Loss: 2.2088499069213867, Total Reward: 1100.0\n",
            "Epoch: 31, Loss: 2.279561758041382, Total Reward: 1100.0\n",
            "Epoch: 32, Loss: 2.375016212463379, Total Reward: 1100.0\n",
            "Epoch: 33, Loss: 2.48272705078125, Total Reward: 1100.0\n",
            "Epoch: 34, Loss: 2.573528289794922, Total Reward: 1100.0\n",
            "Epoch: 35, Loss: 2.687664747238159, Total Reward: 1100.0\n",
            "Epoch: 36, Loss: 2.797970771789551, Total Reward: 1100.0\n",
            "Epoch: 37, Loss: 2.917309522628784, Total Reward: 1100.0\n",
            "Epoch: 38, Loss: 2.9898767471313477, Total Reward: 1100.0\n",
            "Epoch: 39, Loss: 3.16971755027771, Total Reward: 1100.0\n",
            "Epoch: 40, Loss: 3.264052629470825, Total Reward: 1100.0\n",
            "Epoch: 41, Loss: 3.3742082118988037, Total Reward: 1100.0\n",
            "Epoch: 42, Loss: 3.4967966079711914, Total Reward: 1100.0\n",
            "Epoch: 43, Loss: 3.6588451862335205, Total Reward: 1100.0\n",
            "Epoch: 44, Loss: 3.8055672645568848, Total Reward: 1100.0\n",
            "Epoch: 45, Loss: 3.915597438812256, Total Reward: 1100.0\n",
            "Epoch: 46, Loss: 4.097203254699707, Total Reward: 1100.0\n",
            "Epoch: 47, Loss: 4.279595851898193, Total Reward: 1100.0\n",
            "Epoch: 48, Loss: 4.402126312255859, Total Reward: 1100.0\n",
            "Epoch: 49, Loss: 4.565596580505371, Total Reward: 1100.0\n",
            "Epoch: 50, Loss: 4.689330101013184, Total Reward: 1100.0\n",
            "Epoch: 51, Loss: 4.874324798583984, Total Reward: 1100.0\n",
            "Epoch: 52, Loss: 5.028787136077881, Total Reward: 1100.0\n",
            "Epoch: 53, Loss: 5.088513374328613, Total Reward: 1100.0\n",
            "Epoch: 54, Loss: 5.304244518280029, Total Reward: 1100.0\n",
            "Epoch: 55, Loss: 5.441638946533203, Total Reward: 1100.0\n",
            "Epoch: 56, Loss: 5.574357509613037, Total Reward: 1100.0\n",
            "Epoch: 57, Loss: 5.749989986419678, Total Reward: 1100.0\n",
            "Epoch: 58, Loss: 5.90427303314209, Total Reward: 1100.0\n",
            "Epoch: 59, Loss: 6.006288528442383, Total Reward: 1100.0\n",
            "Epoch: 60, Loss: 6.087752342224121, Total Reward: 1100.0\n",
            "Epoch: 61, Loss: 6.381361961364746, Total Reward: 1100.0\n",
            "Epoch: 62, Loss: 6.263017654418945, Total Reward: 1100.0\n",
            "Epoch: 63, Loss: 6.562252044677734, Total Reward: 1100.0\n",
            "Epoch: 64, Loss: 6.525099754333496, Total Reward: 1100.0\n",
            "Epoch: 65, Loss: 6.633537292480469, Total Reward: 1100.0\n",
            "Epoch: 66, Loss: 6.726493835449219, Total Reward: 1100.0\n",
            "Epoch: 67, Loss: 6.814760684967041, Total Reward: 1100.0\n",
            "Epoch: 68, Loss: 6.966986179351807, Total Reward: 1100.0\n",
            "Epoch: 69, Loss: 7.000585556030273, Total Reward: 1100.0\n",
            "Epoch: 70, Loss: 6.940337657928467, Total Reward: 1100.0\n",
            "Epoch: 71, Loss: 7.0804219245910645, Total Reward: 1100.0\n",
            "Epoch: 72, Loss: 6.893031120300293, Total Reward: 1100.0\n",
            "Epoch: 73, Loss: 6.940311431884766, Total Reward: 1100.0\n",
            "Epoch: 74, Loss: 6.999100208282471, Total Reward: 1100.0\n",
            "Epoch: 75, Loss: 6.930731296539307, Total Reward: 1100.0\n",
            "Epoch: 76, Loss: 6.8959550857543945, Total Reward: 1100.0\n",
            "Epoch: 77, Loss: 7.216192245483398, Total Reward: 1000.0\n",
            "Epoch: 78, Loss: 6.719218730926514, Total Reward: 1100.0\n",
            "Epoch: 79, Loss: 6.705894470214844, Total Reward: 1100.0\n",
            "Epoch: 80, Loss: 6.5702385902404785, Total Reward: 1100.0\n",
            "Epoch: 81, Loss: 6.53700065612793, Total Reward: 1100.0\n",
            "Epoch: 82, Loss: 6.30786657333374, Total Reward: 1100.0\n",
            "Epoch: 83, Loss: 6.260620594024658, Total Reward: 1100.0\n",
            "Epoch: 84, Loss: 6.1372857093811035, Total Reward: 1100.0\n",
            "Epoch: 85, Loss: 5.962461471557617, Total Reward: 1100.0\n",
            "Epoch: 86, Loss: 5.816507816314697, Total Reward: 1100.0\n",
            "Epoch: 87, Loss: 5.66317081451416, Total Reward: 1100.0\n",
            "Epoch: 88, Loss: 5.451477527618408, Total Reward: 1100.0\n",
            "Epoch: 89, Loss: 5.276186466217041, Total Reward: 1100.0\n",
            "Epoch: 90, Loss: 5.1872334480285645, Total Reward: 1100.0\n",
            "Epoch: 91, Loss: 4.999342918395996, Total Reward: 1100.0\n",
            "Epoch: 92, Loss: 4.863901138305664, Total Reward: 1100.0\n",
            "Epoch: 93, Loss: 4.678390979766846, Total Reward: 1100.0\n",
            "Epoch: 94, Loss: 4.518328666687012, Total Reward: 1100.0\n",
            "Epoch: 95, Loss: 4.361414909362793, Total Reward: 1100.0\n",
            "Epoch: 96, Loss: 4.207760334014893, Total Reward: 1100.0\n",
            "Epoch: 97, Loss: 4.09881591796875, Total Reward: 1100.0\n",
            "Epoch: 98, Loss: 3.937302827835083, Total Reward: 1100.0\n",
            "Epoch: 99, Loss: 3.7689497470855713, Total Reward: 1100.0\n",
            "Epoch: 100, Loss: 3.6517417430877686, Total Reward: 1100.0\n",
            "Epoch: 101, Loss: 3.525730848312378, Total Reward: 1100.0\n",
            "Epoch: 102, Loss: 3.4200894832611084, Total Reward: 1100.0\n",
            "Epoch: 103, Loss: 3.2604568004608154, Total Reward: 1100.0\n",
            "Epoch: 104, Loss: 3.123697519302368, Total Reward: 1100.0\n",
            "Epoch: 105, Loss: 3.002859354019165, Total Reward: 1100.0\n",
            "Epoch: 106, Loss: 2.89083194732666, Total Reward: 1100.0\n",
            "Epoch: 107, Loss: 2.749199628829956, Total Reward: 1100.0\n",
            "Epoch: 108, Loss: 2.628835439682007, Total Reward: 1100.0\n",
            "Epoch: 109, Loss: 2.503667116165161, Total Reward: 1100.0\n",
            "Epoch: 110, Loss: 2.3799943923950195, Total Reward: 1100.0\n",
            "Epoch: 111, Loss: 2.256612777709961, Total Reward: 1100.0\n",
            "Epoch: 112, Loss: 2.1075804233551025, Total Reward: 1100.0\n",
            "Epoch: 113, Loss: 2.0136523246765137, Total Reward: 1100.0\n",
            "Epoch: 114, Loss: 1.8806242942810059, Total Reward: 1100.0\n",
            "Epoch: 115, Loss: 1.779769778251648, Total Reward: 1100.0\n",
            "Epoch: 116, Loss: 1.6614946126937866, Total Reward: 1100.0\n",
            "Epoch: 117, Loss: 1.5889711380004883, Total Reward: 1100.0\n",
            "Epoch: 118, Loss: 1.4852969646453857, Total Reward: 1100.0\n",
            "Epoch: 119, Loss: 1.409990906715393, Total Reward: 1100.0\n",
            "Epoch: 120, Loss: 1.3179864883422852, Total Reward: 1100.0\n",
            "Epoch: 121, Loss: 1.2226313352584839, Total Reward: 1100.0\n",
            "Epoch: 122, Loss: 1.1390204429626465, Total Reward: 1100.0\n",
            "Epoch: 123, Loss: 1.0717841386795044, Total Reward: 1100.0\n",
            "Epoch: 124, Loss: 0.9781692624092102, Total Reward: 1100.0\n",
            "Epoch: 125, Loss: 0.8944711089134216, Total Reward: 1100.0\n",
            "Epoch: 126, Loss: 0.8221408724784851, Total Reward: 1100.0\n",
            "Epoch: 127, Loss: 0.7610483765602112, Total Reward: 1100.0\n",
            "Epoch: 128, Loss: 0.7085159420967102, Total Reward: 1100.0\n",
            "Epoch: 129, Loss: 0.6035705804824829, Total Reward: 1100.0\n",
            "Epoch: 130, Loss: 0.5532750487327576, Total Reward: 1100.0\n",
            "Epoch: 131, Loss: 0.5100900530815125, Total Reward: 1100.0\n",
            "Epoch: 132, Loss: 0.45881181955337524, Total Reward: 1100.0\n",
            "Epoch: 133, Loss: 0.40120869874954224, Total Reward: 1100.0\n",
            "Epoch: 134, Loss: 0.3627960681915283, Total Reward: 1100.0\n",
            "Epoch: 135, Loss: 0.31993353366851807, Total Reward: 1100.0\n",
            "Epoch: 136, Loss: 0.2900221347808838, Total Reward: 1100.0\n",
            "Epoch: 137, Loss: 0.2611907124519348, Total Reward: 1100.0\n",
            "Epoch: 138, Loss: 0.2299494594335556, Total Reward: 1100.0\n",
            "Epoch: 139, Loss: 0.21416358649730682, Total Reward: 1100.0\n",
            "Epoch: 140, Loss: 0.19611458480358124, Total Reward: 1100.0\n",
            "Epoch: 141, Loss: 0.1648460030555725, Total Reward: 1000.0\n",
            "Epoch: 142, Loss: 0.1502535045146942, Total Reward: 1100.0\n",
            "Epoch: 143, Loss: 0.1309945285320282, Total Reward: 1100.0\n",
            "Epoch: 144, Loss: 0.11885267496109009, Total Reward: 1100.0\n",
            "Epoch: 145, Loss: 0.11230847239494324, Total Reward: 1100.0\n",
            "Epoch: 146, Loss: 0.11318312585353851, Total Reward: 1100.0\n",
            "Epoch: 147, Loss: 0.11193445324897766, Total Reward: 1100.0\n",
            "Epoch: 148, Loss: 0.10762377828359604, Total Reward: 1100.0\n",
            "Epoch: 149, Loss: 0.10720865428447723, Total Reward: 1100.0\n",
            "Epoch: 150, Loss: 0.10664860904216766, Total Reward: 1100.0\n",
            "Epoch: 151, Loss: 0.10604339092969894, Total Reward: 1100.0\n",
            "Epoch: 152, Loss: 0.11337703466415405, Total Reward: 1100.0\n",
            "Epoch: 153, Loss: 0.1325313150882721, Total Reward: 1100.0\n",
            "Epoch: 154, Loss: 0.13779079914093018, Total Reward: 1100.0\n",
            "Epoch: 155, Loss: 0.1567571461200714, Total Reward: 1100.0\n",
            "Epoch: 156, Loss: 0.18529383838176727, Total Reward: 1100.0\n",
            "Epoch: 157, Loss: 0.19092266261577606, Total Reward: 1100.0\n",
            "Epoch: 158, Loss: 0.21063664555549622, Total Reward: 1100.0\n",
            "Epoch: 159, Loss: 0.2528720200061798, Total Reward: 1100.0\n",
            "Epoch: 160, Loss: 0.2891837954521179, Total Reward: 1100.0\n",
            "Epoch: 161, Loss: 0.32504552602767944, Total Reward: 1100.0\n",
            "Epoch: 162, Loss: 0.33477672934532166, Total Reward: 1200.0\n",
            "Epoch: 163, Loss: 0.40442103147506714, Total Reward: 1200.0\n",
            "Epoch: 164, Loss: 0.46529826521873474, Total Reward: 1200.0\n",
            "Epoch: 165, Loss: 0.5182791352272034, Total Reward: 1200.0\n",
            "Epoch: 166, Loss: 0.49526652693748474, Total Reward: 1300.0\n",
            "Epoch: 167, Loss: 0.5582103729248047, Total Reward: 1200.0\n",
            "Epoch: 168, Loss: 0.5636469721794128, Total Reward: 1300.0\n",
            "Epoch: 169, Loss: 0.6465585827827454, Total Reward: 1300.0\n",
            "Epoch: 170, Loss: 0.7080599069595337, Total Reward: 1300.0\n",
            "Epoch: 171, Loss: 0.784931480884552, Total Reward: 1300.0\n",
            "Epoch: 172, Loss: 0.7976343035697937, Total Reward: 1300.0\n",
            "Epoch: 173, Loss: 0.7747188210487366, Total Reward: 1400.0\n",
            "Epoch: 174, Loss: 0.826751708984375, Total Reward: 1400.0\n",
            "Epoch: 175, Loss: 0.875213623046875, Total Reward: 1400.0\n",
            "Epoch: 176, Loss: 0.9770148396492004, Total Reward: 1400.0\n",
            "Epoch: 177, Loss: 1.0344469547271729, Total Reward: 1500.0\n",
            "Epoch: 178, Loss: 1.1084141731262207, Total Reward: 1500.0\n",
            "Epoch: 179, Loss: 1.1611289978027344, Total Reward: 1500.0\n",
            "Epoch: 180, Loss: 1.15496826171875, Total Reward: 1600.0\n",
            "Epoch: 181, Loss: 1.1514431238174438, Total Reward: 1700.0\n",
            "Epoch: 182, Loss: 1.1722332239151, Total Reward: 1700.0\n",
            "Epoch: 183, Loss: 1.2596756219863892, Total Reward: 1700.0\n",
            "Epoch: 184, Loss: 1.325822353363037, Total Reward: 1700.0\n",
            "Epoch: 185, Loss: 1.4344154596328735, Total Reward: 1700.0\n",
            "Epoch: 186, Loss: 1.4998524188995361, Total Reward: 1700.0\n",
            "Epoch: 187, Loss: 1.510709285736084, Total Reward: 1900.0\n",
            "Epoch: 188, Loss: 1.609300136566162, Total Reward: 1800.0\n",
            "Epoch: 189, Loss: 1.6368844509124756, Total Reward: 1900.0\n",
            "Epoch: 190, Loss: 1.6914055347442627, Total Reward: 1900.0\n",
            "Epoch: 191, Loss: 1.6732702255249023, Total Reward: 2100.0\n",
            "Epoch: 192, Loss: 1.7703616619110107, Total Reward: 2000.0\n",
            "Epoch: 193, Loss: 1.7584612369537354, Total Reward: 2200.0\n",
            "Epoch: 194, Loss: 1.8921345472335815, Total Reward: 2100.0\n",
            "Epoch: 195, Loss: 1.8828644752502441, Total Reward: 2300.0\n",
            "Epoch: 196, Loss: 1.9816144704818726, Total Reward: 2200.0\n",
            "Epoch: 197, Loss: 1.9607247114181519, Total Reward: 2400.0\n",
            "Epoch: 198, Loss: 2.132589340209961, Total Reward: 2200.0\n",
            "Epoch: 199, Loss: 2.213797092437744, Total Reward: 2200.0\n",
            "Epoch: 200, Loss: 2.314714193344116, Total Reward: 2200.0\n",
            "Epoch: 201, Loss: 2.4433536529541016, Total Reward: 2200.0\n",
            "Epoch: 202, Loss: 2.4860215187072754, Total Reward: 2300.0\n",
            "Epoch: 203, Loss: 2.582733631134033, Total Reward: 2300.0\n",
            "Epoch: 204, Loss: 2.8311727046966553, Total Reward: 2200.0\n",
            "Epoch: 205, Loss: 2.98199725151062, Total Reward: 2200.0\n",
            "Epoch: 206, Loss: 3.1571550369262695, Total Reward: 2200.0\n",
            "Epoch: 207, Loss: 3.4135165214538574, Total Reward: 2100.0\n",
            "Epoch: 208, Loss: 3.6434898376464844, Total Reward: 2000.0\n",
            "Epoch: 209, Loss: 3.753634452819824, Total Reward: 2000.0\n",
            "Epoch: 210, Loss: 4.092494487762451, Total Reward: 1900.0\n",
            "Epoch: 211, Loss: 4.5257415771484375, Total Reward: 1800.0\n",
            "Epoch: 212, Loss: 5.184983730316162, Total Reward: 1700.0\n",
            "Epoch: 213, Loss: 5.299901008605957, Total Reward: 1700.0\n",
            "Epoch: 214, Loss: 5.631672382354736, Total Reward: 1600.0\n",
            "Epoch: 215, Loss: 6.507873058319092, Total Reward: 1500.0\n",
            "Epoch: 216, Loss: 7.631929397583008, Total Reward: 1400.0\n",
            "Epoch: 217, Loss: 8.106182098388672, Total Reward: 1300.0\n",
            "Epoch: 218, Loss: 9.032352447509766, Total Reward: 1300.0\n",
            "Epoch: 219, Loss: 9.959664344787598, Total Reward: 1200.0\n",
            "Epoch: 220, Loss: 10.896078109741211, Total Reward: 1200.0\n",
            "Epoch: 221, Loss: 12.539332389831543, Total Reward: 1100.0\n",
            "Epoch: 222, Loss: 12.580004692077637, Total Reward: 1100.0\n",
            "Epoch: 223, Loss: 12.974663734436035, Total Reward: 1100.0\n",
            "Epoch: 224, Loss: 13.085301399230957, Total Reward: 1100.0\n",
            "Epoch: 225, Loss: 12.091099739074707, Total Reward: 1100.0\n",
            "Epoch: 226, Loss: 11.222334861755371, Total Reward: 1100.0\n",
            "Epoch: 227, Loss: 10.093578338623047, Total Reward: 1100.0\n",
            "Epoch: 228, Loss: 8.84164047241211, Total Reward: 1100.0\n",
            "Epoch: 229, Loss: 7.49496603012085, Total Reward: 1100.0\n",
            "Epoch: 230, Loss: 6.348025321960449, Total Reward: 1100.0\n",
            "Epoch: 231, Loss: 5.266952037811279, Total Reward: 1100.0\n",
            "Epoch: 232, Loss: 4.346612453460693, Total Reward: 1100.0\n",
            "Epoch: 233, Loss: 3.580307960510254, Total Reward: 1100.0\n",
            "Epoch: 234, Loss: 2.969810724258423, Total Reward: 1100.0\n",
            "Epoch: 235, Loss: 2.3836510181427, Total Reward: 1100.0\n",
            "Epoch: 236, Loss: 1.9123867750167847, Total Reward: 1100.0\n",
            "Epoch: 237, Loss: 1.5951443910598755, Total Reward: 1100.0\n",
            "Epoch: 238, Loss: 1.36318039894104, Total Reward: 1100.0\n",
            "Epoch: 239, Loss: 1.1598740816116333, Total Reward: 1100.0\n",
            "Epoch: 240, Loss: 0.9856957793235779, Total Reward: 1100.0\n",
            "Epoch: 241, Loss: 0.892353892326355, Total Reward: 1100.0\n",
            "Epoch: 242, Loss: 0.8462626338005066, Total Reward: 1100.0\n",
            "Epoch: 243, Loss: 0.8234572410583496, Total Reward: 1100.0\n",
            "Epoch: 244, Loss: 0.79648756980896, Total Reward: 1100.0\n",
            "Epoch: 245, Loss: 0.724061131477356, Total Reward: 1200.0\n",
            "Epoch: 246, Loss: 0.796445906162262, Total Reward: 1200.0\n",
            "Epoch: 247, Loss: 0.853676974773407, Total Reward: 1200.0\n",
            "Epoch: 248, Loss: 0.9222302436828613, Total Reward: 1200.0\n",
            "Epoch: 249, Loss: 0.9252492189407349, Total Reward: 1200.0\n",
            "Epoch: 250, Loss: 0.9112423658370972, Total Reward: 1200.0\n",
            "Epoch: 251, Loss: 0.9483361840248108, Total Reward: 1200.0\n",
            "Epoch: 252, Loss: 1.0652718544006348, Total Reward: 1300.0\n",
            "Epoch: 253, Loss: 1.1536043882369995, Total Reward: 1300.0\n",
            "Epoch: 254, Loss: 1.1732741594314575, Total Reward: 1300.0\n",
            "Epoch: 255, Loss: 1.1966371536254883, Total Reward: 1400.0\n",
            "Epoch: 256, Loss: 1.2492257356643677, Total Reward: 1400.0\n",
            "Epoch: 257, Loss: 1.243931531906128, Total Reward: 1400.0\n",
            "Epoch: 258, Loss: 1.3135828971862793, Total Reward: 1400.0\n",
            "Epoch: 259, Loss: 1.3768906593322754, Total Reward: 1400.0\n",
            "Epoch: 260, Loss: 1.5218591690063477, Total Reward: 1500.0\n",
            "Epoch: 261, Loss: 1.5623971223831177, Total Reward: 1500.0\n",
            "Epoch: 262, Loss: 1.6300442218780518, Total Reward: 1600.0\n",
            "Epoch: 263, Loss: 1.652270793914795, Total Reward: 1600.0\n",
            "Epoch: 264, Loss: 1.590433955192566, Total Reward: 1600.0\n",
            "Epoch: 265, Loss: 1.6310960054397583, Total Reward: 1700.0\n",
            "Epoch: 266, Loss: 1.7123981714248657, Total Reward: 1700.0\n",
            "Epoch: 267, Loss: 1.6899077892303467, Total Reward: 1800.0\n",
            "Epoch: 268, Loss: 1.732526421546936, Total Reward: 1700.0\n",
            "Epoch: 269, Loss: 1.7796368598937988, Total Reward: 1800.0\n",
            "Epoch: 270, Loss: 1.9076552391052246, Total Reward: 1900.0\n",
            "Epoch: 271, Loss: 1.9987127780914307, Total Reward: 1900.0\n",
            "Epoch: 272, Loss: 2.0687386989593506, Total Reward: 2000.0\n",
            "Epoch: 273, Loss: 2.079041004180908, Total Reward: 1900.0\n",
            "Epoch: 274, Loss: 2.1181581020355225, Total Reward: 2000.0\n",
            "Epoch: 275, Loss: 2.01033091545105, Total Reward: 2000.0\n",
            "Epoch: 276, Loss: 2.0649521350860596, Total Reward: 2300.0\n",
            "Epoch: 277, Loss: 2.068413019180298, Total Reward: 2400.0\n",
            "Epoch: 278, Loss: 2.0611624717712402, Total Reward: 2400.0\n",
            "Epoch: 279, Loss: 1.9673596620559692, Total Reward: 2400.0\n",
            "Epoch: 280, Loss: 1.9991812705993652, Total Reward: 2400.0\n",
            "Epoch: 281, Loss: 2.0649642944335938, Total Reward: 2400.0\n",
            "Epoch: 282, Loss: 2.0456383228302, Total Reward: 2500.0\n",
            "Epoch: 283, Loss: 2.0555965900421143, Total Reward: 2600.0\n",
            "Epoch: 284, Loss: 2.210932731628418, Total Reward: 2700.0\n",
            "Epoch: 285, Loss: 2.328411340713501, Total Reward: 2900.0\n",
            "Epoch: 286, Loss: 2.3828787803649902, Total Reward: 2900.0\n",
            "Epoch: 287, Loss: 2.5045857429504395, Total Reward: 3100.0\n",
            "Epoch: 288, Loss: 2.532531499862671, Total Reward: 3100.0\n",
            "Epoch: 289, Loss: 2.4861040115356445, Total Reward: 3300.0\n",
            "Epoch: 290, Loss: 2.5587644577026367, Total Reward: 3200.0\n",
            "Epoch: 291, Loss: 2.418504238128662, Total Reward: 3600.0\n",
            "Epoch: 292, Loss: 2.2548675537109375, Total Reward: 3600.0\n",
            "Epoch: 293, Loss: 2.2185521125793457, Total Reward: 3500.0\n",
            "Epoch: 294, Loss: 2.182708978652954, Total Reward: 3700.0\n",
            "Epoch: 295, Loss: 2.0728251934051514, Total Reward: 3800.0\n",
            "Epoch: 296, Loss: 2.11049222946167, Total Reward: 3800.0\n",
            "Epoch: 297, Loss: 2.0998153686523438, Total Reward: 3600.0\n",
            "Epoch: 298, Loss: 2.172013998031616, Total Reward: 4000.0\n",
            "Epoch: 299, Loss: 2.222529888153076, Total Reward: 4400.0\n",
            "Epoch: 300, Loss: 2.292919874191284, Total Reward: 4200.0\n",
            "Epoch: 301, Loss: 2.3319904804229736, Total Reward: 4900.0\n",
            "Epoch: 302, Loss: 2.5081772804260254, Total Reward: 4400.0\n",
            "Epoch: 303, Loss: 2.501850128173828, Total Reward: 5200.0\n",
            "Epoch: 304, Loss: 2.618468761444092, Total Reward: 6100.0\n",
            "Epoch: 305, Loss: 2.6781575679779053, Total Reward: 10800.0\n",
            "Epoch: 306, Loss: 2.637235164642334, Total Reward: 7500.0\n",
            "Epoch: 307, Loss: 2.6916847229003906, Total Reward: 17200.0\n",
            "Epoch: 308, Loss: 2.6178486347198486, Total Reward: 15800.0\n",
            "Epoch: 309, Loss: 2.572157621383667, Total Reward: 17000.0\n",
            "Epoch: 310, Loss: 2.4555811882019043, Total Reward: 19200.0\n",
            "Epoch: 311, Loss: 2.3348517417907715, Total Reward: 18800.0\n",
            "Epoch: 312, Loss: 2.212514877319336, Total Reward: 14200.0\n",
            "Epoch: 313, Loss: 2.176103353500366, Total Reward: 16400.0\n",
            "Epoch: 314, Loss: 2.1496903896331787, Total Reward: 23400.0\n",
            "Epoch: 315, Loss: 2.244945764541626, Total Reward: 30300.0\n",
            "Epoch: 316, Loss: 2.3333218097686768, Total Reward: 50000.0\n",
            "Epoch: 317, Loss: 2.4079794883728027, Total Reward: 50000.0\n",
            "Epoch: 318, Loss: 2.3522531986236572, Total Reward: 40600.0\n",
            "Epoch: 319, Loss: 2.2796943187713623, Total Reward: 50000.0\n",
            "Epoch: 320, Loss: 2.2975308895111084, Total Reward: 50000.0\n",
            "Epoch: 321, Loss: 2.345578670501709, Total Reward: 50000.0\n",
            "Epoch: 322, Loss: 2.7327394485473633, Total Reward: 50000.0\n",
            "Epoch: 323, Loss: 2.9511475563049316, Total Reward: 17400.0\n",
            "Epoch: 324, Loss: 3.0526130199432373, Total Reward: 50000.0\n",
            "Epoch: 325, Loss: 3.152677059173584, Total Reward: 22500.0\n",
            "Epoch: 326, Loss: 3.5956928730010986, Total Reward: 22100.0\n",
            "Epoch: 327, Loss: 3.8984858989715576, Total Reward: 7900.0\n",
            "Epoch: 328, Loss: 4.80518102645874, Total Reward: 4400.0\n",
            "Epoch: 329, Loss: 6.836388111114502, Total Reward: 3000.0\n",
            "Epoch: 330, Loss: 9.948295593261719, Total Reward: 2200.0\n",
            "Epoch: 331, Loss: 14.069666862487793, Total Reward: 1700.0\n",
            "Epoch: 332, Loss: 21.883602142333984, Total Reward: 1300.0\n",
            "Epoch: 333, Loss: 36.803916931152344, Total Reward: 1100.0\n",
            "Epoch: 334, Loss: 37.21211624145508, Total Reward: 1100.0\n",
            "Epoch: 335, Loss: 36.482391357421875, Total Reward: 1100.0\n",
            "Epoch: 336, Loss: 34.61200714111328, Total Reward: 1100.0\n",
            "Epoch: 337, Loss: 32.13699722290039, Total Reward: 1100.0\n",
            "Epoch: 338, Loss: 29.844940185546875, Total Reward: 1100.0\n",
            "Epoch: 339, Loss: 27.740646362304688, Total Reward: 1100.0\n",
            "Epoch: 340, Loss: 24.94669532775879, Total Reward: 1100.0\n",
            "Epoch: 341, Loss: 21.936311721801758, Total Reward: 1100.0\n",
            "Epoch: 342, Loss: 19.500276565551758, Total Reward: 1100.0\n",
            "Epoch: 343, Loss: 17.476909637451172, Total Reward: 1100.0\n",
            "Epoch: 344, Loss: 15.39014720916748, Total Reward: 1100.0\n",
            "Epoch: 345, Loss: 14.060103416442871, Total Reward: 1100.0\n",
            "Epoch: 346, Loss: 12.485923767089844, Total Reward: 1100.0\n",
            "Epoch: 347, Loss: 10.849717140197754, Total Reward: 1100.0\n",
            "Epoch: 348, Loss: 9.393815040588379, Total Reward: 1100.0\n",
            "Epoch: 349, Loss: 8.012008666992188, Total Reward: 1100.0\n",
            "Epoch: 350, Loss: 6.7662248611450195, Total Reward: 1100.0\n",
            "Epoch: 351, Loss: 5.614725112915039, Total Reward: 1100.0\n",
            "Epoch: 352, Loss: 4.609217643737793, Total Reward: 1100.0\n",
            "Epoch: 353, Loss: 3.718252182006836, Total Reward: 1100.0\n",
            "Epoch: 354, Loss: 2.9323792457580566, Total Reward: 1100.0\n",
            "Epoch: 355, Loss: 2.363400459289551, Total Reward: 1100.0\n",
            "Epoch: 356, Loss: 2.024728775024414, Total Reward: 1100.0\n",
            "Epoch: 357, Loss: 1.575208067893982, Total Reward: 1100.0\n",
            "Epoch: 358, Loss: 1.0892137289047241, Total Reward: 1100.0\n",
            "Epoch: 359, Loss: 0.7752851843833923, Total Reward: 1100.0\n",
            "Epoch: 360, Loss: 0.5511839985847473, Total Reward: 1100.0\n",
            "Epoch: 361, Loss: 0.42793411016464233, Total Reward: 1100.0\n",
            "Epoch: 362, Loss: 0.3469722867012024, Total Reward: 1100.0\n",
            "Epoch: 363, Loss: 0.2855615019798279, Total Reward: 1100.0\n",
            "Epoch: 364, Loss: 0.2605361044406891, Total Reward: 1100.0\n",
            "Epoch: 365, Loss: 0.27333298325538635, Total Reward: 1100.0\n",
            "Epoch: 366, Loss: 0.30442702770233154, Total Reward: 1100.0\n",
            "Epoch: 367, Loss: 0.3486520051956177, Total Reward: 1100.0\n",
            "Epoch: 368, Loss: 0.3982367217540741, Total Reward: 1100.0\n",
            "Epoch: 369, Loss: 0.47636640071868896, Total Reward: 1100.0\n",
            "Epoch: 370, Loss: 0.5193875432014465, Total Reward: 1100.0\n",
            "Epoch: 371, Loss: 0.5918264985084534, Total Reward: 1100.0\n",
            "Epoch: 372, Loss: 0.654413104057312, Total Reward: 1100.0\n",
            "Epoch: 373, Loss: 0.694002628326416, Total Reward: 1100.0\n",
            "Epoch: 374, Loss: 0.709866464138031, Total Reward: 1100.0\n",
            "Epoch: 375, Loss: 0.7663665413856506, Total Reward: 1100.0\n",
            "Epoch: 376, Loss: 0.7641775608062744, Total Reward: 1100.0\n",
            "Epoch: 377, Loss: 0.770876407623291, Total Reward: 1100.0\n",
            "Epoch: 378, Loss: 0.7671454548835754, Total Reward: 1100.0\n",
            "Epoch: 379, Loss: 0.7334998250007629, Total Reward: 1100.0\n",
            "Epoch: 380, Loss: 0.7219429612159729, Total Reward: 1100.0\n",
            "Epoch: 381, Loss: 0.6893316507339478, Total Reward: 1100.0\n",
            "Epoch: 382, Loss: 0.6364718079566956, Total Reward: 1100.0\n",
            "Epoch: 383, Loss: 0.5969738960266113, Total Reward: 1100.0\n",
            "Epoch: 384, Loss: 0.5541223287582397, Total Reward: 1100.0\n",
            "Epoch: 385, Loss: 0.4854171872138977, Total Reward: 1000.0\n",
            "Epoch: 386, Loss: 0.4736790359020233, Total Reward: 1100.0\n",
            "Epoch: 387, Loss: 0.4140391945838928, Total Reward: 1100.0\n",
            "Epoch: 388, Loss: 0.3835204541683197, Total Reward: 1100.0\n",
            "Epoch: 389, Loss: 0.33551228046417236, Total Reward: 1100.0\n",
            "Epoch: 390, Loss: 0.32582688331604004, Total Reward: 1100.0\n",
            "Epoch: 391, Loss: 0.28723809123039246, Total Reward: 1100.0\n",
            "Epoch: 392, Loss: 0.26484036445617676, Total Reward: 1100.0\n",
            "Epoch: 393, Loss: 0.24709098041057587, Total Reward: 1100.0\n",
            "Epoch: 394, Loss: 0.24158744513988495, Total Reward: 1100.0\n",
            "Epoch: 395, Loss: 0.2309536337852478, Total Reward: 1100.0\n",
            "Epoch: 396, Loss: 0.22680453956127167, Total Reward: 1100.0\n",
            "Epoch: 397, Loss: 0.22273604571819305, Total Reward: 1100.0\n",
            "Epoch: 398, Loss: 0.23212258517742157, Total Reward: 1100.0\n",
            "Epoch: 399, Loss: 0.24000178277492523, Total Reward: 1100.0\n",
            "Epoch: 400, Loss: 0.2504987120628357, Total Reward: 1100.0\n",
            "Epoch: 401, Loss: 0.26831844449043274, Total Reward: 1100.0\n",
            "Epoch: 402, Loss: 0.28479063510894775, Total Reward: 1100.0\n",
            "Epoch: 403, Loss: 0.3074507713317871, Total Reward: 1100.0\n",
            "Epoch: 404, Loss: 0.33058270812034607, Total Reward: 1100.0\n",
            "Epoch: 405, Loss: 0.35583558678627014, Total Reward: 1100.0\n",
            "Epoch: 406, Loss: 0.3824866712093353, Total Reward: 1100.0\n",
            "Epoch: 407, Loss: 0.41069430112838745, Total Reward: 1100.0\n",
            "Epoch: 408, Loss: 0.43750956654548645, Total Reward: 1100.0\n",
            "Epoch: 409, Loss: 0.4671802222728729, Total Reward: 1100.0\n",
            "Epoch: 410, Loss: 0.4989507496356964, Total Reward: 1100.0\n",
            "Epoch: 411, Loss: 0.5265281796455383, Total Reward: 1100.0\n",
            "Epoch: 412, Loss: 0.5593754053115845, Total Reward: 1100.0\n",
            "Epoch: 413, Loss: 0.588346004486084, Total Reward: 1100.0\n",
            "Epoch: 414, Loss: 0.6157358884811401, Total Reward: 1100.0\n",
            "Epoch: 415, Loss: 0.6527754664421082, Total Reward: 1100.0\n",
            "Epoch: 416, Loss: 0.6738847494125366, Total Reward: 1100.0\n",
            "Epoch: 417, Loss: 0.7029061317443848, Total Reward: 1100.0\n",
            "Epoch: 418, Loss: 0.7321742177009583, Total Reward: 1100.0\n",
            "Epoch: 419, Loss: 0.7605799436569214, Total Reward: 1100.0\n",
            "Epoch: 420, Loss: 0.7882369756698608, Total Reward: 1100.0\n",
            "Epoch: 421, Loss: 0.8131583333015442, Total Reward: 1100.0\n",
            "Epoch: 422, Loss: 0.8308682441711426, Total Reward: 1100.0\n",
            "Epoch: 423, Loss: 0.8489896655082703, Total Reward: 1100.0\n",
            "Epoch: 424, Loss: 0.8706557750701904, Total Reward: 1100.0\n",
            "Epoch: 425, Loss: 0.886597216129303, Total Reward: 1100.0\n",
            "Epoch: 426, Loss: 0.8964967131614685, Total Reward: 1100.0\n",
            "Epoch: 427, Loss: 0.912283718585968, Total Reward: 1100.0\n",
            "Epoch: 428, Loss: 0.9251267313957214, Total Reward: 1100.0\n",
            "Epoch: 429, Loss: 0.9340937733650208, Total Reward: 1100.0\n",
            "Epoch: 430, Loss: 0.9445106387138367, Total Reward: 1100.0\n",
            "Epoch: 431, Loss: 0.9452585577964783, Total Reward: 1100.0\n",
            "Epoch: 432, Loss: 0.9553309082984924, Total Reward: 1100.0\n",
            "Epoch: 433, Loss: 0.9542803168296814, Total Reward: 1100.0\n",
            "Epoch: 434, Loss: 0.9587705135345459, Total Reward: 1100.0\n",
            "Epoch: 435, Loss: 0.9562036991119385, Total Reward: 1100.0\n",
            "Epoch: 436, Loss: 0.9588867425918579, Total Reward: 1100.0\n",
            "Epoch: 437, Loss: 0.9575947523117065, Total Reward: 1100.0\n",
            "Epoch: 438, Loss: 0.948866069316864, Total Reward: 1100.0\n",
            "Epoch: 439, Loss: 0.9409207701683044, Total Reward: 1100.0\n",
            "Epoch: 440, Loss: 0.9375167489051819, Total Reward: 1100.0\n",
            "Epoch: 441, Loss: 0.9283694624900818, Total Reward: 1100.0\n",
            "Epoch: 442, Loss: 0.9286488890647888, Total Reward: 1100.0\n",
            "Epoch: 443, Loss: 0.9094904065132141, Total Reward: 1100.0\n",
            "Epoch: 444, Loss: 0.8999884724617004, Total Reward: 1100.0\n",
            "Epoch: 445, Loss: 0.8967512249946594, Total Reward: 1100.0\n",
            "Epoch: 446, Loss: 0.8886449337005615, Total Reward: 1100.0\n",
            "Epoch: 447, Loss: 0.8677391409873962, Total Reward: 1100.0\n",
            "Epoch: 448, Loss: 0.851152777671814, Total Reward: 1100.0\n",
            "Epoch: 449, Loss: 0.8411034345626831, Total Reward: 1100.0\n",
            "Epoch: 450, Loss: 0.8312709331512451, Total Reward: 1100.0\n",
            "Epoch: 451, Loss: 0.8064973950386047, Total Reward: 1100.0\n",
            "Epoch: 452, Loss: 0.7975316047668457, Total Reward: 1100.0\n",
            "Epoch: 453, Loss: 0.7818640470504761, Total Reward: 1100.0\n",
            "Epoch: 454, Loss: 0.7621082663536072, Total Reward: 1100.0\n",
            "Epoch: 455, Loss: 0.7446545958518982, Total Reward: 1100.0\n",
            "Epoch: 456, Loss: 0.7307946085929871, Total Reward: 1100.0\n",
            "Epoch: 457, Loss: 0.7260186076164246, Total Reward: 1100.0\n",
            "Epoch: 458, Loss: 0.7009113430976868, Total Reward: 1100.0\n",
            "Epoch: 459, Loss: 0.688149094581604, Total Reward: 1100.0\n",
            "Epoch: 460, Loss: 0.6652567982673645, Total Reward: 1100.0\n",
            "Epoch: 461, Loss: 0.6470178365707397, Total Reward: 1100.0\n",
            "Epoch: 462, Loss: 0.6429293155670166, Total Reward: 1100.0\n",
            "Epoch: 463, Loss: 0.6226874589920044, Total Reward: 1100.0\n",
            "Epoch: 464, Loss: 0.6035507321357727, Total Reward: 1100.0\n",
            "Epoch: 465, Loss: 0.5958665609359741, Total Reward: 1100.0\n",
            "Epoch: 466, Loss: 0.5842418670654297, Total Reward: 1100.0\n",
            "Epoch: 467, Loss: 0.5823822021484375, Total Reward: 1100.0\n",
            "Epoch: 468, Loss: 0.56388920545578, Total Reward: 1100.0\n",
            "Epoch: 469, Loss: 0.5476632714271545, Total Reward: 1100.0\n",
            "Epoch: 470, Loss: 0.52881920337677, Total Reward: 1100.0\n",
            "Epoch: 471, Loss: 0.5164101719856262, Total Reward: 1100.0\n",
            "Epoch: 472, Loss: 0.5125181078910828, Total Reward: 1100.0\n",
            "Epoch: 473, Loss: 0.5028465390205383, Total Reward: 1100.0\n",
            "Epoch: 474, Loss: 0.49749699234962463, Total Reward: 1100.0\n",
            "Epoch: 475, Loss: 0.480729877948761, Total Reward: 1100.0\n",
            "Epoch: 476, Loss: 0.46746569871902466, Total Reward: 1100.0\n",
            "Epoch: 477, Loss: 0.4545581638813019, Total Reward: 1100.0\n",
            "Epoch: 478, Loss: 0.4495793879032135, Total Reward: 1100.0\n",
            "Epoch: 479, Loss: 0.44280731678009033, Total Reward: 1100.0\n",
            "Epoch: 480, Loss: 0.4368453621864319, Total Reward: 1100.0\n",
            "Epoch: 481, Loss: 0.41960829496383667, Total Reward: 1100.0\n",
            "Epoch: 482, Loss: 0.41806450486183167, Total Reward: 1100.0\n",
            "Epoch: 483, Loss: 0.4031111001968384, Total Reward: 1100.0\n",
            "Epoch: 484, Loss: 0.3890005648136139, Total Reward: 1100.0\n",
            "Epoch: 485, Loss: 0.37350597977638245, Total Reward: 1100.0\n",
            "Epoch: 486, Loss: 0.395027756690979, Total Reward: 1100.0\n",
            "Epoch: 487, Loss: 0.3630797266960144, Total Reward: 1100.0\n",
            "Epoch: 488, Loss: 0.3695887625217438, Total Reward: 1100.0\n",
            "Epoch: 489, Loss: 0.3479679226875305, Total Reward: 1100.0\n",
            "Epoch: 490, Loss: 0.34539544582366943, Total Reward: 1100.0\n",
            "Epoch: 491, Loss: 0.3406224250793457, Total Reward: 1100.0\n",
            "Epoch: 492, Loss: 0.3320562541484833, Total Reward: 1100.0\n",
            "Epoch: 493, Loss: 0.3119414448738098, Total Reward: 1100.0\n",
            "Epoch: 494, Loss: 0.3255372941493988, Total Reward: 1100.0\n",
            "Epoch: 495, Loss: 0.31418171525001526, Total Reward: 1100.0\n",
            "Epoch: 496, Loss: 0.3152996003627777, Total Reward: 1100.0\n",
            "Epoch: 497, Loss: 0.29886648058891296, Total Reward: 1100.0\n",
            "Epoch: 498, Loss: 0.2957538366317749, Total Reward: 1100.0\n",
            "Epoch: 499, Loss: 0.3059071898460388, Total Reward: 1100.0\n",
            "Epoch: 500, Loss: 0.3000711500644684, Total Reward: 1100.0\n",
            "Epoch: 501, Loss: 0.2944328784942627, Total Reward: 1100.0\n",
            "Epoch: 502, Loss: 0.27811717987060547, Total Reward: 1100.0\n",
            "Epoch: 503, Loss: 0.30197736620903015, Total Reward: 1000.0\n",
            "Epoch: 504, Loss: 0.25901439785957336, Total Reward: 1100.0\n",
            "Epoch: 505, Loss: 0.25721362233161926, Total Reward: 1100.0\n",
            "Epoch: 506, Loss: 0.2705811560153961, Total Reward: 1100.0\n",
            "Epoch: 507, Loss: 0.2589932382106781, Total Reward: 1100.0\n",
            "Epoch: 508, Loss: 0.25573867559432983, Total Reward: 1100.0\n",
            "Epoch: 509, Loss: 0.2520561218261719, Total Reward: 1100.0\n",
            "Epoch: 510, Loss: 0.23622189462184906, Total Reward: 1100.0\n",
            "Epoch: 511, Loss: 0.24803386628627777, Total Reward: 1100.0\n",
            "Epoch: 512, Loss: 0.23436343669891357, Total Reward: 1100.0\n",
            "Epoch: 513, Loss: 0.22509470582008362, Total Reward: 1100.0\n",
            "Epoch: 514, Loss: 0.2539839446544647, Total Reward: 1100.0\n",
            "Epoch: 515, Loss: 0.2231893241405487, Total Reward: 1100.0\n",
            "Epoch: 516, Loss: 0.21981903910636902, Total Reward: 1100.0\n",
            "Epoch: 517, Loss: 0.22895999252796173, Total Reward: 1000.0\n",
            "Epoch: 518, Loss: 0.22022807598114014, Total Reward: 1100.0\n",
            "Epoch: 519, Loss: 0.22211289405822754, Total Reward: 1100.0\n",
            "Epoch: 520, Loss: 0.22441710531711578, Total Reward: 1100.0\n",
            "Epoch: 521, Loss: 0.19838029146194458, Total Reward: 1100.0\n",
            "Epoch: 522, Loss: 0.2090301513671875, Total Reward: 1100.0\n",
            "Epoch: 523, Loss: 0.2015060931444168, Total Reward: 1100.0\n",
            "Epoch: 524, Loss: 0.18470680713653564, Total Reward: 1100.0\n",
            "Epoch: 525, Loss: 0.17556431889533997, Total Reward: 1100.0\n",
            "Epoch: 526, Loss: 0.18849343061447144, Total Reward: 1100.0\n",
            "Epoch: 527, Loss: 0.20517316460609436, Total Reward: 1100.0\n",
            "Epoch: 528, Loss: 0.18481120467185974, Total Reward: 1100.0\n",
            "Epoch: 529, Loss: 0.18808138370513916, Total Reward: 1100.0\n",
            "Epoch: 530, Loss: 0.1766207218170166, Total Reward: 1100.0\n",
            "Epoch: 531, Loss: 0.16995365917682648, Total Reward: 1100.0\n",
            "Epoch: 532, Loss: 0.17452189326286316, Total Reward: 1100.0\n",
            "Epoch: 533, Loss: 0.1806648224592209, Total Reward: 1100.0\n",
            "Epoch: 534, Loss: 0.17208123207092285, Total Reward: 1100.0\n",
            "Epoch: 535, Loss: 0.18221823871135712, Total Reward: 1100.0\n",
            "Epoch: 536, Loss: 0.18830670416355133, Total Reward: 1100.0\n",
            "Epoch: 537, Loss: 0.178466334939003, Total Reward: 1100.0\n",
            "Epoch: 538, Loss: 0.17608767747879028, Total Reward: 1100.0\n",
            "Epoch: 539, Loss: 0.17092972993850708, Total Reward: 1100.0\n",
            "Epoch: 540, Loss: 0.17073385417461395, Total Reward: 1100.0\n",
            "Epoch: 541, Loss: 0.18501567840576172, Total Reward: 1100.0\n",
            "Epoch: 542, Loss: 0.17851302027702332, Total Reward: 1100.0\n",
            "Epoch: 543, Loss: 0.1804625391960144, Total Reward: 1100.0\n",
            "Epoch: 544, Loss: 0.16341792047023773, Total Reward: 1100.0\n",
            "Epoch: 545, Loss: 0.15890581905841827, Total Reward: 1100.0\n",
            "Epoch: 546, Loss: 0.1651054173707962, Total Reward: 1100.0\n",
            "Epoch: 547, Loss: 0.14911505579948425, Total Reward: 1100.0\n",
            "Epoch: 548, Loss: 0.15361548960208893, Total Reward: 1100.0\n",
            "Epoch: 549, Loss: 0.14817854762077332, Total Reward: 1100.0\n",
            "Epoch: 550, Loss: 0.15503135323524475, Total Reward: 1100.0\n",
            "Epoch: 551, Loss: 0.13765621185302734, Total Reward: 1100.0\n",
            "Epoch: 552, Loss: 0.15056516230106354, Total Reward: 1100.0\n",
            "Epoch: 553, Loss: 0.15200267732143402, Total Reward: 1100.0\n",
            "Epoch: 554, Loss: 0.14796175062656403, Total Reward: 1100.0\n",
            "Epoch: 555, Loss: 0.12643367052078247, Total Reward: 1100.0\n",
            "Epoch: 556, Loss: 0.13632705807685852, Total Reward: 1100.0\n",
            "Epoch: 557, Loss: 0.12659060955047607, Total Reward: 1100.0\n",
            "Epoch: 558, Loss: 0.11733967065811157, Total Reward: 1100.0\n",
            "Epoch: 559, Loss: 0.14499063789844513, Total Reward: 1100.0\n",
            "Epoch: 560, Loss: 0.1406448632478714, Total Reward: 1100.0\n",
            "Epoch: 561, Loss: 0.1421068161725998, Total Reward: 1100.0\n",
            "Epoch: 562, Loss: 0.14794275164604187, Total Reward: 1000.0\n",
            "Epoch: 563, Loss: 0.12671540677547455, Total Reward: 1100.0\n",
            "Epoch: 564, Loss: 0.12220647931098938, Total Reward: 1100.0\n",
            "Epoch: 565, Loss: 0.13484106957912445, Total Reward: 1100.0\n",
            "Epoch: 566, Loss: 0.1323186457157135, Total Reward: 1100.0\n",
            "Epoch: 567, Loss: 0.11724584549665451, Total Reward: 1100.0\n",
            "Epoch: 568, Loss: 0.11435902863740921, Total Reward: 1100.0\n",
            "Epoch: 569, Loss: 0.13681402802467346, Total Reward: 1100.0\n",
            "Epoch: 570, Loss: 0.12288884818553925, Total Reward: 1100.0\n",
            "Epoch: 571, Loss: 0.12181593477725983, Total Reward: 1100.0\n",
            "Epoch: 572, Loss: 0.1134728342294693, Total Reward: 1100.0\n",
            "Epoch: 573, Loss: 0.11613748222589493, Total Reward: 1100.0\n",
            "Epoch: 574, Loss: 0.11722610145807266, Total Reward: 1100.0\n",
            "Epoch: 575, Loss: 0.10398498177528381, Total Reward: 1100.0\n",
            "Epoch: 576, Loss: 0.12866923213005066, Total Reward: 1100.0\n",
            "Epoch: 577, Loss: 0.12539678812026978, Total Reward: 1100.0\n",
            "Epoch: 578, Loss: 0.11878088861703873, Total Reward: 1100.0\n",
            "Epoch: 579, Loss: 0.11659818887710571, Total Reward: 1100.0\n",
            "Epoch: 580, Loss: 0.10715988278388977, Total Reward: 1100.0\n",
            "Epoch: 581, Loss: 0.10568556934595108, Total Reward: 1100.0\n",
            "Epoch: 582, Loss: 0.10686725378036499, Total Reward: 1100.0\n",
            "Epoch: 583, Loss: 0.10469251126050949, Total Reward: 1100.0\n",
            "Epoch: 584, Loss: 0.127388596534729, Total Reward: 1100.0\n",
            "Epoch: 585, Loss: 0.10787178575992584, Total Reward: 1100.0\n",
            "Epoch: 586, Loss: 0.12485481798648834, Total Reward: 1100.0\n",
            "Epoch: 587, Loss: 0.11043771356344223, Total Reward: 1100.0\n",
            "Epoch: 588, Loss: 0.10469555854797363, Total Reward: 1100.0\n",
            "Epoch: 589, Loss: 0.10058216750621796, Total Reward: 1100.0\n",
            "Epoch: 590, Loss: 0.10661199688911438, Total Reward: 1100.0\n",
            "Epoch: 591, Loss: 0.11801570653915405, Total Reward: 1100.0\n",
            "Epoch: 592, Loss: 0.10974272340536118, Total Reward: 1100.0\n",
            "Epoch: 593, Loss: 0.1210484579205513, Total Reward: 1100.0\n",
            "Epoch: 594, Loss: 0.09580802917480469, Total Reward: 1100.0\n",
            "Epoch: 595, Loss: 0.09275630116462708, Total Reward: 1100.0\n",
            "Epoch: 596, Loss: 0.10536547005176544, Total Reward: 1100.0\n",
            "Epoch: 597, Loss: 0.10231935977935791, Total Reward: 1100.0\n",
            "Epoch: 598, Loss: 0.10201267898082733, Total Reward: 1100.0\n",
            "Epoch: 599, Loss: 0.10582270473241806, Total Reward: 1100.0\n",
            "Epoch: 600, Loss: 0.09676375985145569, Total Reward: 1100.0\n",
            "Epoch: 601, Loss: 0.0851895734667778, Total Reward: 1100.0\n",
            "Epoch: 602, Loss: 0.1011931300163269, Total Reward: 1100.0\n",
            "Epoch: 603, Loss: 0.0966019332408905, Total Reward: 1100.0\n",
            "Epoch: 604, Loss: 0.09252583235502243, Total Reward: 1100.0\n",
            "Epoch: 605, Loss: 0.11220086365938187, Total Reward: 1000.0\n",
            "Epoch: 606, Loss: 0.09827573597431183, Total Reward: 1100.0\n",
            "Epoch: 607, Loss: 0.0898689329624176, Total Reward: 1100.0\n",
            "Epoch: 608, Loss: 0.09780099242925644, Total Reward: 1100.0\n",
            "Epoch: 609, Loss: 0.08997279405593872, Total Reward: 1100.0\n",
            "Epoch: 610, Loss: 0.09640692919492722, Total Reward: 1100.0\n",
            "Epoch: 611, Loss: 0.10576073825359344, Total Reward: 1100.0\n",
            "Epoch: 612, Loss: 0.09828478842973709, Total Reward: 1100.0\n",
            "Epoch: 613, Loss: 0.10033620148897171, Total Reward: 1100.0\n",
            "Epoch: 614, Loss: 0.09029534459114075, Total Reward: 1100.0\n",
            "Epoch: 615, Loss: 0.0945616364479065, Total Reward: 1100.0\n",
            "Epoch: 616, Loss: 0.09306850284337997, Total Reward: 1100.0\n",
            "Epoch: 617, Loss: 0.08382327109575272, Total Reward: 1100.0\n",
            "Epoch: 618, Loss: 0.08508706837892532, Total Reward: 1100.0\n",
            "Epoch: 619, Loss: 0.08419722318649292, Total Reward: 1100.0\n",
            "Epoch: 620, Loss: 0.07841571420431137, Total Reward: 1100.0\n",
            "Epoch: 621, Loss: 0.07756288349628448, Total Reward: 1100.0\n",
            "Epoch: 622, Loss: 0.09031732380390167, Total Reward: 1100.0\n",
            "Epoch: 623, Loss: 0.08192045986652374, Total Reward: 1100.0\n",
            "Epoch: 624, Loss: 0.07803186029195786, Total Reward: 1100.0\n",
            "Epoch: 625, Loss: 0.09282135963439941, Total Reward: 1100.0\n",
            "Epoch: 626, Loss: 0.08015639334917068, Total Reward: 1100.0\n",
            "Epoch: 627, Loss: 0.08692841976881027, Total Reward: 1100.0\n",
            "Epoch: 628, Loss: 0.09300728887319565, Total Reward: 1100.0\n",
            "Epoch: 629, Loss: 0.09984580427408218, Total Reward: 1100.0\n",
            "Epoch: 630, Loss: 0.07379966974258423, Total Reward: 1100.0\n",
            "Epoch: 631, Loss: 0.079823799431324, Total Reward: 1100.0\n",
            "Epoch: 632, Loss: 0.08156204968690872, Total Reward: 1100.0\n",
            "Epoch: 633, Loss: 0.08441279083490372, Total Reward: 1100.0\n",
            "Epoch: 634, Loss: 0.07863565534353256, Total Reward: 1100.0\n",
            "Epoch: 635, Loss: 0.08638210594654083, Total Reward: 1100.0\n",
            "Epoch: 636, Loss: 0.0718325525522232, Total Reward: 1100.0\n",
            "Epoch: 637, Loss: 0.06970471888780594, Total Reward: 1100.0\n",
            "Epoch: 638, Loss: 0.0635317787528038, Total Reward: 1100.0\n",
            "Epoch: 639, Loss: 0.07241642475128174, Total Reward: 1100.0\n",
            "Epoch: 640, Loss: 0.07507513463497162, Total Reward: 1100.0\n",
            "Epoch: 641, Loss: 0.08398670703172684, Total Reward: 1100.0\n",
            "Epoch: 642, Loss: 0.07010982185602188, Total Reward: 1100.0\n",
            "Epoch: 643, Loss: 0.06967645138502121, Total Reward: 1100.0\n",
            "Epoch: 644, Loss: 0.061199214309453964, Total Reward: 1100.0\n",
            "Epoch: 645, Loss: 0.06794368475675583, Total Reward: 1100.0\n",
            "Epoch: 646, Loss: 0.07028181850910187, Total Reward: 1100.0\n",
            "Epoch: 647, Loss: 0.07120519131422043, Total Reward: 1100.0\n",
            "Epoch: 648, Loss: 0.0763792097568512, Total Reward: 1100.0\n",
            "Epoch: 649, Loss: 0.06992135941982269, Total Reward: 1100.0\n",
            "Epoch: 650, Loss: 0.09400515258312225, Total Reward: 1100.0\n",
            "Epoch: 651, Loss: 0.08093372732400894, Total Reward: 1100.0\n",
            "Epoch: 652, Loss: 0.07606545090675354, Total Reward: 1100.0\n",
            "Epoch: 653, Loss: 0.0844307467341423, Total Reward: 1100.0\n",
            "Epoch: 654, Loss: 0.08081890642642975, Total Reward: 1100.0\n",
            "Epoch: 655, Loss: 0.06956488639116287, Total Reward: 1100.0\n",
            "Epoch: 656, Loss: 0.06574926525354385, Total Reward: 1100.0\n",
            "Epoch: 657, Loss: 0.06694266945123672, Total Reward: 1100.0\n",
            "Epoch: 658, Loss: 0.07749304175376892, Total Reward: 1100.0\n",
            "Epoch: 659, Loss: 0.07196802645921707, Total Reward: 1100.0\n",
            "Epoch: 660, Loss: 0.09316808730363846, Total Reward: 1100.0\n",
            "Epoch: 661, Loss: 0.07738378643989563, Total Reward: 1100.0\n",
            "Epoch: 662, Loss: 0.06797550618648529, Total Reward: 1100.0\n",
            "Epoch: 663, Loss: 0.07793822139501572, Total Reward: 1100.0\n",
            "Epoch: 664, Loss: 0.06628638505935669, Total Reward: 1100.0\n",
            "Epoch: 665, Loss: 0.07429564744234085, Total Reward: 1100.0\n",
            "Epoch: 666, Loss: 0.08379688113927841, Total Reward: 1100.0\n",
            "Epoch: 667, Loss: 0.0661543607711792, Total Reward: 1100.0\n",
            "Epoch: 668, Loss: 0.08075225353240967, Total Reward: 1100.0\n",
            "Epoch: 669, Loss: 0.07178864628076553, Total Reward: 1100.0\n",
            "Epoch: 670, Loss: 0.06787877529859543, Total Reward: 1100.0\n",
            "Epoch: 671, Loss: 0.056000955402851105, Total Reward: 1100.0\n",
            "Epoch: 672, Loss: 0.06513790786266327, Total Reward: 1100.0\n",
            "Epoch: 673, Loss: 0.06911362707614899, Total Reward: 1100.0\n",
            "Epoch: 674, Loss: 0.07360300421714783, Total Reward: 1100.0\n",
            "Epoch: 675, Loss: 0.06917738914489746, Total Reward: 1100.0\n",
            "Epoch: 676, Loss: 0.06457021832466125, Total Reward: 1100.0\n",
            "Epoch: 677, Loss: 0.05848370119929314, Total Reward: 1100.0\n",
            "Epoch: 678, Loss: 0.05810529366135597, Total Reward: 1100.0\n",
            "Epoch: 679, Loss: 0.06396307051181793, Total Reward: 1100.0\n",
            "Epoch: 680, Loss: 0.060568030923604965, Total Reward: 1100.0\n",
            "Epoch: 681, Loss: 0.06008314713835716, Total Reward: 1100.0\n",
            "Epoch: 682, Loss: 0.04871765524148941, Total Reward: 1100.0\n",
            "Epoch: 683, Loss: 0.06507309526205063, Total Reward: 1100.0\n",
            "Epoch: 684, Loss: 0.07124558091163635, Total Reward: 1100.0\n",
            "Epoch: 685, Loss: 0.06669279932975769, Total Reward: 1100.0\n",
            "Epoch: 686, Loss: 0.04971117898821831, Total Reward: 1100.0\n",
            "Epoch: 687, Loss: 0.06208394095301628, Total Reward: 1100.0\n",
            "Epoch: 688, Loss: 0.057957641780376434, Total Reward: 1100.0\n",
            "Epoch: 689, Loss: 0.05801427364349365, Total Reward: 1100.0\n",
            "Epoch: 690, Loss: 0.055514462292194366, Total Reward: 1100.0\n",
            "Epoch: 691, Loss: 0.053132250905036926, Total Reward: 1100.0\n",
            "Epoch: 692, Loss: 0.06909573823213577, Total Reward: 1100.0\n",
            "Epoch: 693, Loss: 0.0630619078874588, Total Reward: 1100.0\n",
            "Epoch: 694, Loss: 0.06034301221370697, Total Reward: 1100.0\n",
            "Epoch: 695, Loss: 0.07004187256097794, Total Reward: 1100.0\n",
            "Epoch: 696, Loss: 0.05268752574920654, Total Reward: 1100.0\n",
            "Epoch: 697, Loss: 0.0662621259689331, Total Reward: 1100.0\n",
            "Epoch: 698, Loss: 0.0648428350687027, Total Reward: 1100.0\n",
            "Epoch: 699, Loss: 0.06326768547296524, Total Reward: 1100.0\n",
            "Epoch: 700, Loss: 0.061705779284238815, Total Reward: 1100.0\n",
            "Epoch: 701, Loss: 0.06600181758403778, Total Reward: 1100.0\n",
            "Epoch: 702, Loss: 0.0697452649474144, Total Reward: 1100.0\n",
            "Epoch: 703, Loss: 0.05686801299452782, Total Reward: 1100.0\n",
            "Epoch: 704, Loss: 0.059971749782562256, Total Reward: 1100.0\n",
            "Epoch: 705, Loss: 0.05446594953536987, Total Reward: 1100.0\n",
            "Epoch: 706, Loss: 0.057498905807733536, Total Reward: 1100.0\n",
            "Epoch: 707, Loss: 0.0549655444920063, Total Reward: 1100.0\n",
            "Epoch: 708, Loss: 0.056790102273225784, Total Reward: 1100.0\n",
            "Epoch: 709, Loss: 0.03976406902074814, Total Reward: 1100.0\n",
            "Epoch: 710, Loss: 0.04860590025782585, Total Reward: 1100.0\n",
            "Epoch: 711, Loss: 0.05790577828884125, Total Reward: 1100.0\n",
            "Epoch: 712, Loss: 0.047452811151742935, Total Reward: 1100.0\n",
            "Epoch: 713, Loss: 0.06458358466625214, Total Reward: 1100.0\n",
            "Epoch: 714, Loss: 0.05752546340227127, Total Reward: 1100.0\n",
            "Epoch: 715, Loss: 0.04568442329764366, Total Reward: 1100.0\n",
            "Epoch: 716, Loss: 0.04535399749875069, Total Reward: 1100.0\n",
            "Epoch: 717, Loss: 0.04877465218305588, Total Reward: 1100.0\n",
            "Epoch: 718, Loss: 0.0577615424990654, Total Reward: 1100.0\n",
            "Epoch: 719, Loss: 0.04475371539592743, Total Reward: 1100.0\n",
            "Epoch: 720, Loss: 0.04703707620501518, Total Reward: 1100.0\n",
            "Epoch: 721, Loss: 0.04868626967072487, Total Reward: 1100.0\n",
            "Epoch: 722, Loss: 0.05348306894302368, Total Reward: 1100.0\n",
            "Epoch: 723, Loss: 0.053884249180555344, Total Reward: 1100.0\n",
            "Epoch: 724, Loss: 0.046741634607315063, Total Reward: 1100.0\n",
            "Epoch: 725, Loss: 0.05964720994234085, Total Reward: 1100.0\n",
            "Epoch: 726, Loss: 0.041560154408216476, Total Reward: 1100.0\n",
            "Epoch: 727, Loss: 0.04351859912276268, Total Reward: 1100.0\n",
            "Epoch: 728, Loss: 0.045617055147886276, Total Reward: 1100.0\n",
            "Epoch: 729, Loss: 0.03974299877882004, Total Reward: 1100.0\n",
            "Epoch: 730, Loss: 0.04636164754629135, Total Reward: 1100.0\n",
            "Epoch: 731, Loss: 0.060417938977479935, Total Reward: 1100.0\n",
            "Epoch: 732, Loss: 0.04613868147134781, Total Reward: 1100.0\n",
            "Epoch: 733, Loss: 0.05135801061987877, Total Reward: 1100.0\n",
            "Epoch: 734, Loss: 0.0531117282807827, Total Reward: 1100.0\n",
            "Epoch: 735, Loss: 0.04817043989896774, Total Reward: 1100.0\n",
            "Epoch: 736, Loss: 0.04739586263895035, Total Reward: 1100.0\n",
            "Epoch: 737, Loss: 0.03886883705854416, Total Reward: 1100.0\n",
            "Epoch: 738, Loss: 0.06261616200208664, Total Reward: 1100.0\n",
            "Epoch: 739, Loss: 0.06068730354309082, Total Reward: 1100.0\n",
            "Epoch: 740, Loss: 0.05147237330675125, Total Reward: 1100.0\n",
            "Epoch: 741, Loss: 0.04771929606795311, Total Reward: 1100.0\n",
            "Epoch: 742, Loss: 0.039171889424324036, Total Reward: 1100.0\n",
            "Epoch: 743, Loss: 0.04842006415128708, Total Reward: 1100.0\n",
            "Epoch: 744, Loss: 0.05480628088116646, Total Reward: 1100.0\n",
            "Epoch: 745, Loss: 0.045325737446546555, Total Reward: 1100.0\n",
            "Epoch: 746, Loss: 0.043182846158742905, Total Reward: 1100.0\n",
            "Epoch: 747, Loss: 0.04913817718625069, Total Reward: 1100.0\n",
            "Epoch: 748, Loss: 0.049771327525377274, Total Reward: 1100.0\n",
            "Epoch: 749, Loss: 0.04762819781899452, Total Reward: 1100.0\n",
            "Epoch: 750, Loss: 0.05544450506567955, Total Reward: 1100.0\n",
            "Epoch: 751, Loss: 0.04513053223490715, Total Reward: 1100.0\n",
            "Epoch: 752, Loss: 0.060569971799850464, Total Reward: 1100.0\n",
            "Epoch: 753, Loss: 0.05060666799545288, Total Reward: 1100.0\n",
            "Epoch: 754, Loss: 0.045556362718343735, Total Reward: 1100.0\n",
            "Epoch: 755, Loss: 0.04941900447010994, Total Reward: 1100.0\n",
            "Epoch: 756, Loss: 0.049231041222810745, Total Reward: 1100.0\n",
            "Epoch: 757, Loss: 0.04766935855150223, Total Reward: 1100.0\n",
            "Epoch: 758, Loss: 0.04345302656292915, Total Reward: 1100.0\n",
            "Epoch: 759, Loss: 0.0401589497923851, Total Reward: 1100.0\n",
            "Epoch: 760, Loss: 0.04461264982819557, Total Reward: 1100.0\n",
            "Epoch: 761, Loss: 0.043315209448337555, Total Reward: 1100.0\n",
            "Epoch: 762, Loss: 0.04887055978178978, Total Reward: 1100.0\n",
            "Epoch: 763, Loss: 0.03723021224141121, Total Reward: 1100.0\n",
            "Epoch: 764, Loss: 0.05365757644176483, Total Reward: 1100.0\n",
            "Epoch: 765, Loss: 0.04650019109249115, Total Reward: 1100.0\n",
            "Epoch: 766, Loss: 0.04588029906153679, Total Reward: 1100.0\n",
            "Epoch: 767, Loss: 0.04000430181622505, Total Reward: 1100.0\n",
            "Epoch: 768, Loss: 0.050138238817453384, Total Reward: 1100.0\n",
            "Epoch: 769, Loss: 0.03827304393053055, Total Reward: 1100.0\n",
            "Epoch: 770, Loss: 0.04529543220996857, Total Reward: 1100.0\n",
            "Epoch: 771, Loss: 0.03929920122027397, Total Reward: 1100.0\n",
            "Epoch: 772, Loss: 0.04365004599094391, Total Reward: 1100.0\n",
            "Epoch: 773, Loss: 0.04445329308509827, Total Reward: 1100.0\n",
            "Epoch: 774, Loss: 0.04161614179611206, Total Reward: 1100.0\n",
            "Epoch: 775, Loss: 0.05187385901808739, Total Reward: 1100.0\n",
            "Epoch: 776, Loss: 0.03513659909367561, Total Reward: 1100.0\n",
            "Epoch: 777, Loss: 0.05192158371210098, Total Reward: 1100.0\n",
            "Epoch: 778, Loss: 0.03641942888498306, Total Reward: 1100.0\n",
            "Epoch: 779, Loss: 0.040542058646678925, Total Reward: 1100.0\n",
            "Epoch: 780, Loss: 0.0367618091404438, Total Reward: 1100.0\n",
            "Epoch: 781, Loss: 0.0392562635242939, Total Reward: 1100.0\n",
            "Epoch: 782, Loss: 0.047883860766887665, Total Reward: 1100.0\n",
            "Epoch: 783, Loss: 0.04255720227956772, Total Reward: 1100.0\n",
            "Epoch: 784, Loss: 0.058449886739254, Total Reward: 1100.0\n",
            "Epoch: 785, Loss: 0.04997539892792702, Total Reward: 1100.0\n",
            "Epoch: 786, Loss: 0.043820299208164215, Total Reward: 1100.0\n",
            "Epoch: 787, Loss: 0.042796790599823, Total Reward: 1100.0\n",
            "Epoch: 788, Loss: 0.05358385294675827, Total Reward: 1100.0\n",
            "Epoch: 789, Loss: 0.04366690292954445, Total Reward: 1100.0\n",
            "Epoch: 790, Loss: 0.041881248354911804, Total Reward: 1100.0\n",
            "Epoch: 791, Loss: 0.04078197106719017, Total Reward: 1100.0\n",
            "Epoch: 792, Loss: 0.05060942471027374, Total Reward: 1000.0\n",
            "Epoch: 793, Loss: 0.05022452399134636, Total Reward: 1100.0\n",
            "Epoch: 794, Loss: 0.035272952169179916, Total Reward: 1100.0\n",
            "Epoch: 795, Loss: 0.04569525271654129, Total Reward: 1100.0\n",
            "Epoch: 796, Loss: 0.05184829235076904, Total Reward: 1100.0\n",
            "Epoch: 797, Loss: 0.04109826683998108, Total Reward: 1100.0\n",
            "Epoch: 798, Loss: 0.03660942614078522, Total Reward: 1100.0\n",
            "Epoch: 799, Loss: 0.039906058460474014, Total Reward: 1100.0\n",
            "Epoch: 800, Loss: 0.04796883836388588, Total Reward: 1100.0\n",
            "Epoch: 801, Loss: 0.03956808149814606, Total Reward: 1100.0\n",
            "Epoch: 802, Loss: 0.03566725179553032, Total Reward: 1100.0\n",
            "Epoch: 803, Loss: 0.04436628893017769, Total Reward: 1100.0\n",
            "Epoch: 804, Loss: 0.043399352580308914, Total Reward: 1100.0\n",
            "Epoch: 805, Loss: 0.03393266722559929, Total Reward: 1100.0\n",
            "Epoch: 806, Loss: 0.034959517419338226, Total Reward: 1100.0\n",
            "Epoch: 807, Loss: 0.04188823699951172, Total Reward: 1100.0\n",
            "Epoch: 808, Loss: 0.040533825755119324, Total Reward: 1100.0\n",
            "Epoch: 809, Loss: 0.033675916492938995, Total Reward: 1100.0\n",
            "Epoch: 810, Loss: 0.030124522745609283, Total Reward: 1100.0\n",
            "Epoch: 811, Loss: 0.03545013815164566, Total Reward: 1100.0\n",
            "Epoch: 812, Loss: 0.0443718321621418, Total Reward: 1100.0\n",
            "Epoch: 813, Loss: 0.041007451713085175, Total Reward: 1100.0\n",
            "Epoch: 814, Loss: 0.03594255447387695, Total Reward: 1100.0\n",
            "Epoch: 815, Loss: 0.04139530286192894, Total Reward: 1100.0\n",
            "Epoch: 816, Loss: 0.03576694056391716, Total Reward: 1100.0\n",
            "Epoch: 817, Loss: 0.0406901054084301, Total Reward: 1100.0\n",
            "Epoch: 818, Loss: 0.044889260083436966, Total Reward: 1100.0\n",
            "Epoch: 819, Loss: 0.030578738078475, Total Reward: 1100.0\n",
            "Epoch: 820, Loss: 0.04096279293298721, Total Reward: 1100.0\n",
            "Epoch: 821, Loss: 0.035238806158304214, Total Reward: 1100.0\n",
            "Epoch: 822, Loss: 0.03821196407079697, Total Reward: 1100.0\n",
            "Epoch: 823, Loss: 0.037722352892160416, Total Reward: 1100.0\n",
            "Epoch: 824, Loss: 0.03322187438607216, Total Reward: 1100.0\n",
            "Epoch: 825, Loss: 0.03486483171582222, Total Reward: 1100.0\n",
            "Epoch: 826, Loss: 0.030716385692358017, Total Reward: 1100.0\n",
            "Epoch: 827, Loss: 0.049751415848731995, Total Reward: 1100.0\n",
            "Epoch: 828, Loss: 0.041773490607738495, Total Reward: 1100.0\n",
            "Epoch: 829, Loss: 0.03745681047439575, Total Reward: 1100.0\n",
            "Epoch: 830, Loss: 0.03951818868517876, Total Reward: 1100.0\n",
            "Epoch: 831, Loss: 0.03997144103050232, Total Reward: 1100.0\n",
            "Epoch: 832, Loss: 0.032309677451848984, Total Reward: 1100.0\n",
            "Epoch: 833, Loss: 0.034418001770973206, Total Reward: 1100.0\n",
            "Epoch: 834, Loss: 0.03030853345990181, Total Reward: 1100.0\n",
            "Epoch: 835, Loss: 0.040543731302022934, Total Reward: 1100.0\n",
            "Epoch: 836, Loss: 0.040077462792396545, Total Reward: 1100.0\n",
            "Epoch: 837, Loss: 0.040080197155475616, Total Reward: 1100.0\n",
            "Epoch: 838, Loss: 0.044956885278224945, Total Reward: 1100.0\n",
            "Epoch: 839, Loss: 0.04190078005194664, Total Reward: 1000.0\n",
            "Epoch: 840, Loss: 0.04976950213313103, Total Reward: 1100.0\n",
            "Epoch: 841, Loss: 0.03865160793066025, Total Reward: 1100.0\n",
            "Epoch: 842, Loss: 0.04212517663836479, Total Reward: 1100.0\n",
            "Epoch: 843, Loss: 0.033855099231004715, Total Reward: 1100.0\n",
            "Epoch: 844, Loss: 0.04144724830985069, Total Reward: 1100.0\n",
            "Epoch: 845, Loss: 0.03919828683137894, Total Reward: 1100.0\n",
            "Epoch: 846, Loss: 0.03415706753730774, Total Reward: 1100.0\n",
            "Epoch: 847, Loss: 0.04694252833724022, Total Reward: 1100.0\n",
            "Epoch: 848, Loss: 0.03806388005614281, Total Reward: 1100.0\n",
            "Epoch: 849, Loss: 0.04619791731238365, Total Reward: 1100.0\n",
            "Epoch: 850, Loss: 0.0387478768825531, Total Reward: 1100.0\n",
            "Epoch: 851, Loss: 0.04445861652493477, Total Reward: 1100.0\n",
            "Epoch: 852, Loss: 0.0463947132229805, Total Reward: 1100.0\n",
            "Epoch: 853, Loss: 0.03507212921977043, Total Reward: 1100.0\n",
            "Epoch: 854, Loss: 0.03733045980334282, Total Reward: 1100.0\n",
            "Epoch: 855, Loss: 0.04133360832929611, Total Reward: 1100.0\n",
            "Epoch: 856, Loss: 0.04140836000442505, Total Reward: 1100.0\n",
            "Epoch: 857, Loss: 0.03905550763010979, Total Reward: 1100.0\n",
            "Epoch: 858, Loss: 0.03612281009554863, Total Reward: 1100.0\n",
            "Epoch: 859, Loss: 0.04447196424007416, Total Reward: 1100.0\n",
            "Epoch: 860, Loss: 0.03335551545023918, Total Reward: 1100.0\n",
            "Epoch: 861, Loss: 0.03483664616942406, Total Reward: 1100.0\n",
            "Epoch: 862, Loss: 0.033086955547332764, Total Reward: 1100.0\n",
            "Epoch: 863, Loss: 0.038296785205602646, Total Reward: 1100.0\n",
            "Epoch: 864, Loss: 0.042930301278829575, Total Reward: 1100.0\n",
            "Epoch: 865, Loss: 0.033971793949604034, Total Reward: 1100.0\n",
            "Epoch: 866, Loss: 0.044158536940813065, Total Reward: 1100.0\n",
            "Epoch: 867, Loss: 0.03143061697483063, Total Reward: 1100.0\n",
            "Epoch: 868, Loss: 0.0348147377371788, Total Reward: 1100.0\n",
            "Epoch: 869, Loss: 0.03361043706536293, Total Reward: 1100.0\n",
            "Epoch: 870, Loss: 0.03339559584856033, Total Reward: 1100.0\n",
            "Epoch: 871, Loss: 0.039385322481393814, Total Reward: 1100.0\n",
            "Epoch: 872, Loss: 0.028775280341506004, Total Reward: 1100.0\n",
            "Epoch: 873, Loss: 0.03368927165865898, Total Reward: 1100.0\n",
            "Epoch: 874, Loss: 0.033359821885824203, Total Reward: 1100.0\n",
            "Epoch: 875, Loss: 0.03527950122952461, Total Reward: 1100.0\n",
            "Epoch: 876, Loss: 0.027066413313150406, Total Reward: 1100.0\n",
            "Epoch: 877, Loss: 0.03209110349416733, Total Reward: 1100.0\n",
            "Epoch: 878, Loss: 0.02711072564125061, Total Reward: 1100.0\n",
            "Epoch: 879, Loss: 0.0358394980430603, Total Reward: 1100.0\n",
            "Epoch: 880, Loss: 0.03386809304356575, Total Reward: 1100.0\n",
            "Epoch: 881, Loss: 0.03611020743846893, Total Reward: 1100.0\n",
            "Epoch: 882, Loss: 0.03212654963135719, Total Reward: 1100.0\n",
            "Epoch: 883, Loss: 0.027770349755883217, Total Reward: 1100.0\n",
            "Epoch: 884, Loss: 0.03380448371171951, Total Reward: 1100.0\n",
            "Epoch: 885, Loss: 0.027319569140672684, Total Reward: 1100.0\n",
            "Epoch: 886, Loss: 0.02514343522489071, Total Reward: 1100.0\n",
            "Epoch: 887, Loss: 0.03139922395348549, Total Reward: 1100.0\n",
            "Epoch: 888, Loss: 0.029176607728004456, Total Reward: 1100.0\n",
            "Epoch: 889, Loss: 0.029050027951598167, Total Reward: 1100.0\n",
            "Epoch: 890, Loss: 0.03661080822348595, Total Reward: 1100.0\n",
            "Epoch: 891, Loss: 0.029190216213464737, Total Reward: 1100.0\n",
            "Epoch: 892, Loss: 0.03459324687719345, Total Reward: 1100.0\n",
            "Epoch: 893, Loss: 0.02729344367980957, Total Reward: 1100.0\n",
            "Epoch: 894, Loss: 0.03908202052116394, Total Reward: 1100.0\n",
            "Epoch: 895, Loss: 0.037156686186790466, Total Reward: 1100.0\n",
            "Epoch: 896, Loss: 0.03302722051739693, Total Reward: 1100.0\n",
            "Epoch: 897, Loss: 0.03577214851975441, Total Reward: 1100.0\n",
            "Epoch: 898, Loss: 0.041424378752708435, Total Reward: 1100.0\n",
            "Epoch: 899, Loss: 0.036625247448682785, Total Reward: 1100.0\n",
            "Epoch: 900, Loss: 0.04096809774637222, Total Reward: 1100.0\n",
            "Epoch: 901, Loss: 0.03351489454507828, Total Reward: 1100.0\n",
            "Epoch: 902, Loss: 0.03211111202836037, Total Reward: 1100.0\n",
            "Epoch: 903, Loss: 0.03631310909986496, Total Reward: 1100.0\n",
            "Epoch: 904, Loss: 0.03620752692222595, Total Reward: 1100.0\n",
            "Epoch: 905, Loss: 0.039564043283462524, Total Reward: 1100.0\n",
            "Epoch: 906, Loss: 0.03947489336133003, Total Reward: 1100.0\n",
            "Epoch: 907, Loss: 0.04028664156794548, Total Reward: 1100.0\n",
            "Epoch: 908, Loss: 0.033475231379270554, Total Reward: 1100.0\n",
            "Epoch: 909, Loss: 0.036720991134643555, Total Reward: 1100.0\n",
            "Epoch: 910, Loss: 0.04007738456130028, Total Reward: 1100.0\n",
            "Epoch: 911, Loss: 0.03566259890794754, Total Reward: 1100.0\n",
            "Epoch: 912, Loss: 0.027128975838422775, Total Reward: 1100.0\n",
            "Epoch: 913, Loss: 0.027949931100010872, Total Reward: 1100.0\n",
            "Epoch: 914, Loss: 0.033952146768569946, Total Reward: 1100.0\n",
            "Epoch: 915, Loss: 0.034238945692777634, Total Reward: 1100.0\n",
            "Epoch: 916, Loss: 0.03611143305897713, Total Reward: 1100.0\n",
            "Epoch: 917, Loss: 0.039245981723070145, Total Reward: 1100.0\n",
            "Epoch: 918, Loss: 0.033741265535354614, Total Reward: 1100.0\n",
            "Epoch: 919, Loss: 0.038697145879268646, Total Reward: 1100.0\n",
            "Epoch: 920, Loss: 0.03270461782813072, Total Reward: 1100.0\n",
            "Epoch: 921, Loss: 0.04113239794969559, Total Reward: 1100.0\n",
            "Epoch: 922, Loss: 0.04051056504249573, Total Reward: 1100.0\n",
            "Epoch: 923, Loss: 0.02767709270119667, Total Reward: 1100.0\n",
            "Epoch: 924, Loss: 0.03173527121543884, Total Reward: 1100.0\n",
            "Epoch: 925, Loss: 0.03661881759762764, Total Reward: 1100.0\n",
            "Epoch: 926, Loss: 0.03461864963173866, Total Reward: 1100.0\n",
            "Epoch: 927, Loss: 0.03851646929979324, Total Reward: 1100.0\n",
            "Epoch: 928, Loss: 0.041155602782964706, Total Reward: 1100.0\n",
            "Epoch: 929, Loss: 0.03449143096804619, Total Reward: 1100.0\n",
            "Epoch: 930, Loss: 0.03174036368727684, Total Reward: 1100.0\n",
            "Epoch: 931, Loss: 0.034873995929956436, Total Reward: 1100.0\n",
            "Epoch: 932, Loss: 0.03919249773025513, Total Reward: 1000.0\n",
            "Epoch: 933, Loss: 0.02952132187783718, Total Reward: 1100.0\n",
            "Epoch: 934, Loss: 0.02739935927093029, Total Reward: 1100.0\n",
            "Epoch: 935, Loss: 0.03290625661611557, Total Reward: 1100.0\n",
            "Epoch: 936, Loss: 0.035375479608774185, Total Reward: 1100.0\n",
            "Epoch: 937, Loss: 0.03008561208844185, Total Reward: 1100.0\n",
            "Epoch: 938, Loss: 0.03829381242394447, Total Reward: 1100.0\n",
            "Epoch: 939, Loss: 0.02604617178440094, Total Reward: 1100.0\n",
            "Epoch: 940, Loss: 0.03312350809574127, Total Reward: 1100.0\n",
            "Epoch: 941, Loss: 0.02738519012928009, Total Reward: 1100.0\n",
            "Epoch: 942, Loss: 0.03236857429146767, Total Reward: 1100.0\n",
            "Epoch: 943, Loss: 0.02337743155658245, Total Reward: 1100.0\n",
            "Epoch: 944, Loss: 0.03342209756374359, Total Reward: 1100.0\n",
            "Epoch: 945, Loss: 0.03492750972509384, Total Reward: 1100.0\n",
            "Epoch: 946, Loss: 0.02812201902270317, Total Reward: 1000.0\n",
            "Epoch: 947, Loss: 0.031530529260635376, Total Reward: 1100.0\n",
            "Epoch: 948, Loss: 0.029892435297369957, Total Reward: 1100.0\n",
            "Epoch: 949, Loss: 0.031534042209386826, Total Reward: 1100.0\n",
            "Epoch: 950, Loss: 0.027770759537816048, Total Reward: 1100.0\n",
            "Epoch: 951, Loss: 0.034580640494823456, Total Reward: 1100.0\n",
            "Epoch: 952, Loss: 0.03362872079014778, Total Reward: 1100.0\n",
            "Epoch: 953, Loss: 0.024024860933423042, Total Reward: 1100.0\n",
            "Epoch: 954, Loss: 0.02933676913380623, Total Reward: 1100.0\n",
            "Epoch: 955, Loss: 0.024930736050009727, Total Reward: 1100.0\n",
            "Epoch: 956, Loss: 0.027729056775569916, Total Reward: 1100.0\n",
            "Epoch: 957, Loss: 0.03689631074666977, Total Reward: 1100.0\n",
            "Epoch: 958, Loss: 0.022079583257436752, Total Reward: 1100.0\n",
            "Epoch: 959, Loss: 0.030661264434456825, Total Reward: 1100.0\n",
            "Epoch: 960, Loss: 0.03403875231742859, Total Reward: 1100.0\n",
            "Epoch: 961, Loss: 0.040138352662324905, Total Reward: 1100.0\n",
            "Epoch: 962, Loss: 0.035910412669181824, Total Reward: 1100.0\n",
            "Epoch: 963, Loss: 0.030260540544986725, Total Reward: 1100.0\n",
            "Epoch: 964, Loss: 0.03821482136845589, Total Reward: 1100.0\n",
            "Epoch: 965, Loss: 0.03266828879714012, Total Reward: 1100.0\n",
            "Epoch: 966, Loss: 0.033148422837257385, Total Reward: 1100.0\n",
            "Epoch: 967, Loss: 0.029352663084864616, Total Reward: 1100.0\n",
            "Epoch: 968, Loss: 0.03294408693909645, Total Reward: 1100.0\n",
            "Epoch: 969, Loss: 0.03088274598121643, Total Reward: 1100.0\n",
            "Epoch: 970, Loss: 0.02989336848258972, Total Reward: 1100.0\n",
            "Epoch: 971, Loss: 0.03450862318277359, Total Reward: 1100.0\n",
            "Epoch: 972, Loss: 0.03727361932396889, Total Reward: 1100.0\n",
            "Epoch: 973, Loss: 0.037118636071681976, Total Reward: 1100.0\n",
            "Epoch: 974, Loss: 0.036246877163648605, Total Reward: 1100.0\n",
            "Epoch: 975, Loss: 0.03643576800823212, Total Reward: 1100.0\n",
            "Epoch: 976, Loss: 0.030067794024944305, Total Reward: 1100.0\n",
            "Epoch: 977, Loss: 0.03382338210940361, Total Reward: 1100.0\n",
            "Epoch: 978, Loss: 0.03723279386758804, Total Reward: 1100.0\n",
            "Epoch: 979, Loss: 0.039646390825510025, Total Reward: 1100.0\n",
            "Epoch: 980, Loss: 0.031471580266952515, Total Reward: 1100.0\n",
            "Epoch: 981, Loss: 0.041845355182886124, Total Reward: 1100.0\n",
            "Epoch: 982, Loss: 0.03712695837020874, Total Reward: 1100.0\n",
            "Epoch: 983, Loss: 0.042436424642801285, Total Reward: 1100.0\n",
            "Epoch: 984, Loss: 0.029242608696222305, Total Reward: 1100.0\n",
            "Epoch: 985, Loss: 0.02835266850888729, Total Reward: 1100.0\n",
            "Epoch: 986, Loss: 0.03567983955144882, Total Reward: 1100.0\n",
            "Epoch: 987, Loss: 0.03181750699877739, Total Reward: 1100.0\n",
            "Epoch: 988, Loss: 0.0413694866001606, Total Reward: 1100.0\n",
            "Epoch: 989, Loss: 0.032295163720846176, Total Reward: 1100.0\n",
            "Epoch: 990, Loss: 0.04049725458025932, Total Reward: 1100.0\n",
            "Epoch: 991, Loss: 0.03287976607680321, Total Reward: 1100.0\n",
            "Epoch: 992, Loss: 0.03560208901762962, Total Reward: 1100.0\n",
            "Epoch: 993, Loss: 0.02455066703259945, Total Reward: 1100.0\n",
            "Epoch: 994, Loss: 0.03184107318520546, Total Reward: 1100.0\n",
            "Epoch: 995, Loss: 0.03364065662026405, Total Reward: 1100.0\n",
            "Epoch: 996, Loss: 0.02872486226260662, Total Reward: 1100.0\n",
            "Epoch: 997, Loss: 0.026767302304506302, Total Reward: 1100.0\n",
            "Epoch: 998, Loss: 0.02561252750456333, Total Reward: 1100.0\n",
            "Epoch: 999, Loss: 0.02349385991692543, Total Reward: 1100.0\n",
            "Epoch: 1000, Loss: 0.039484377950429916, Total Reward: 1100.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FBEtRvvWZP7i"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}